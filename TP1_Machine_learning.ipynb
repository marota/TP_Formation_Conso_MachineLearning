{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le problème : la prévision de consommation électrique\n",
    "\n",
    "Pour garantir l'équilibre offre-demande à chaque instant et gérer l'acheminement de l'électricité, RTE construit ses propres prévisions de la consommation nationale, régionale, et locale, à différentes échéances de temps (de l'infrajournalier au pluri-annuel).\n",
    "\n",
    "Ici on se focalise sur un problème particulier : **la prévision de la consommation électrique nationale horaire à horizon J+1** (on suppose qu'on connaît toutes les données jusqu'au jour J inclus). \n",
    "\n",
    "## Les données : Eco2mix\n",
    "\n",
    "La courbe de charge France est disponible sur eco2mix :\n",
    "http://www.rte-france.com/fr/eco2mix/eco2mix\n",
    "ou sur application mobile.\n",
    "\n",
    "Vous pouvez naviguer sur le site pour vous familiariser avec les données sur lesquelles vous allez travailler.\n",
    "\n",
    "## Objectif :\n",
    "\n",
    "Au cours de ce TP, nous allons aborder les différentes étapes nécessaires à la construction d'un modèle de prévision de consommation :\n",
    "\n",
    "1) Formalisation du problème: que souhaite-t-on prédire (quel est mon Y) ? Avec quelles variables explicatives (quel est mon X) ?\n",
    "\n",
    "2) Collecte des données: où se trouvent les données ? Quel est le format ? Comment les récupérer ? (FACULTATIF - voir TP \"TP1_Preparation_donnees\")\n",
    "\n",
    "3) Import des données et analyses descriptives : visualiser des séries temporelles, statistiques descriptives\n",
    "\n",
    "4) Transformation des données (feature engineering) pour entrainer et tester un premier modèle\n",
    "\n",
    "5) Création de prévision à dire d'expert pour servir de référence.\n",
    "\n",
    "6) Découpage des données : apprentissage - test\n",
    "\n",
    "7) Evaluer un modèle\n",
    "\n",
    "8) Tester des algorithmes de référence : régression linéaire, forêts aléatoires, xgboost\n",
    "\n",
    "9) Itérer à partir des modèles testés pour améliorer les prévisions\n",
    "\n",
    "Nous verrons qu'une difficulté majeure réside dans la construction des \"bonnes\" variables explicatives (\"garbage in, garbage out\").\n",
    "\n",
    "**Le notebook est parsemé de questions (<font color='green'>en vert</font>). Vous pouvez y répondre sur la feuille fournie.**\n",
    "\n",
    "## Méthodes de prévision considérées\n",
    "\n",
    "Les modèles actuels reposent sur des méthodes de régression linéaire et non-linéaire. Nous étudierons ici les limites de la régression linéaire.\n",
    "\n",
    "Pour améliorer les prévisions, nous aurons recours aux méthodes dites de Machine Learning. Ces méthodes ne dépendent pas d'une formalisation a priori du lien entre les variables explicatives X et la variable à expliquer Y. \n",
    "Elles sont souvent moins interprétables mais peuvent être plus efficaces en prévision. Elles peuvent nécessiter plus de temps de calcul et plus de données pour cela.\n",
    "\n",
    "Construire un bon modèle d'apprentissage nécessite en général de la connaissance experte dans le domaine d'intérêt pour créer des modèles pertinents et efficaces. \n",
    "\n",
    "## To be continued : deep learning\n",
    "\n",
    "Le deuxième TP permettra d'investiguer les modèles \"Deep\" avec réseaux de neurones, en montrant le moindre besoin en feature engineering et leur plus grande capacité à absorber l'information grâce aux représentations hiérarchiques qu'ils créent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environnement de travail \n",
    "\n",
    "Ceci est un notebook jupyter. Il permet d'exécuter du code python, d'afficher des résultats et d'écrire du texte pour décrire l'ensemble de l'étude.\n",
    "\n",
    "<font color='red'>\n",
    "    \n",
    "**NB : L'aide de python est accessible en tapant help(nom_de_la_commande)**\n",
    "\n",
    "</font>\n",
    "\n",
    "## Chargement des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz in d:\\users\\montuelleluc\\documents\\portable\\anaconda\\lib\\site-packages (2019.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "# Exécutez la cellule ci-dessous (par exemple avec shift-entrée)\n",
    "# Si vous exécuter ce notebook depuis votre PC, il faudra peut-etre installer certaines librairies avec \n",
    "# 'pip install ma_librairie'\n",
    "import os  # accès aux commandes système\n",
    "\n",
    "import datetime  # structure de données pour gérer des objets calendaires\n",
    "from datetime import timezone\n",
    "import pandas as pd  # gérer des tables de données en python\n",
    "import numpy as np  # librairie d'opérations mathématiques\n",
    "from math import sqrt\n",
    "\n",
    "import pytz\n",
    "\n",
    "import sklearn  # librairie de machine learning\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot, iplot_mpl\n",
    "import matplotlib.pyplot as plt  # tracer des visualisations\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import zipfile  # compresser ou décompresser fichier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données disponibles\n",
    "\n",
    "Choix du répertoire de travail \"data_folder\" dans lequel tous les fichiers csv seront entreposés. Ici le répertoire s'appelle *data*.\n",
    "\n",
    "Ensuite on affiche les fichiers du répertoire pour vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.getcwd(), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon repertoire est : D:\\Users\\montuelleluc\\Documents\\Formations-RTE\\MOOC IA&DeepLearning\\TP_Formation_Conso_DeepLearning\\data\n",
      "Fichiers contenus dans ce répertoire :\n",
      " - communes_coordonnees.csv\n",
      " - eCO2mix_RTE_tempo_2017-2018.xls\n",
      " - joursFeries.csv\n",
      " - meteoX_T0_T24.zip\n",
      " - StationsMeteoRTE.csv\n",
      " - Xinput.csv\n",
      " - Xinput.zip\n",
      " - Xtemperature.csv\n",
      " - Xtemperature.zip\n",
      " - Yconso.csv\n",
      " - YconsoT0.csv\n",
      " - Yconso_2014_2018.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Mon repertoire est : {}\".format(data_folder))\n",
    "print(\"Fichiers contenus dans ce répertoire :\")\n",
    "for file in os.listdir(data_folder):\n",
    "    print(\" - \" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des données dans Python\n",
    "\n",
    "Dans cette partie nous allons charger les fichiers csv nécessaires pour l'analyse, puis les convertir en data-frame python : \n",
    "- Yconso.csv\n",
    "- Xinput.csv\n",
    "\n",
    "Rappel : Les données brutes ont été pré-traitées à l'aide du notebook *TP1_Preparation_donnees.ipynb* pour obtenir ces deux fichiers.\n",
    "\n",
    "## import de Yconso.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-08 00:00:00+00:00</td>\n",
       "      <td>62008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-08 01:00:00+00:00</td>\n",
       "      <td>57298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-08 02:00:00+00:00</td>\n",
       "      <td>56216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-08 03:00:00+00:00</td>\n",
       "      <td>53719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-08 04:00:00+00:00</td>\n",
       "      <td>51798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ds      y\n",
       "0  2014-01-08 00:00:00+00:00  62008\n",
       "1  2014-01-08 01:00:00+00:00  57298\n",
       "2  2014-01-08 02:00:00+00:00  56216\n",
       "3  2014-01-08 03:00:00+00:00  53719\n",
       "4  2014-01-08 04:00:00+00:00  51798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds    object\n",
      "y      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "Yconso_csv = os.path.join(data_folder, \"Yconso.csv\")\n",
    "Yconso = pd.read_csv(Yconso_csv)\n",
    "display(Yconso.head(5)) # affichage des premières lignes\n",
    "print(Yconso.dtypes) # affichage du type de données pour chaque colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne \"ds\" contient la date, mais celle-ci n'est pas reconnue en tant que telle mais en tant que chaîne de caractères (https://pbpython.com/pandas_dtypes.html). On va la convertir en objet de type \"datetime\" plus approprié pour extraire des informations comme le jour de la semaine ou l'heure.  \n",
    "Pour plus d'information, voir le TP1_Preparation_donnees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds    datetime64[ns, UTC]\n",
      "y                   int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-08 00:00:00+00:00</td>\n",
       "      <td>62008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-08 01:00:00+00:00</td>\n",
       "      <td>57298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-08 02:00:00+00:00</td>\n",
       "      <td>56216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-08 03:00:00+00:00</td>\n",
       "      <td>53719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-08 04:00:00+00:00</td>\n",
       "      <td>51798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ds      y\n",
       "0 2014-01-08 00:00:00+00:00  62008\n",
       "1 2014-01-08 01:00:00+00:00  57298\n",
       "2 2014-01-08 02:00:00+00:00  56216\n",
       "3 2014-01-08 03:00:00+00:00  53719\n",
       "4 2014-01-08 04:00:00+00:00  51798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Yconso['ds'] = pd.to_datetime(Yconso['ds'],utc=True)\n",
    "print(Yconso.dtypes)\n",
    "display(Yconso.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visuellemement cela ne change rien.\n",
    "\n",
    "On peut aussi afficher la dimension du DataFrame (toujours s'assurer que cela correspond aux valeurs attendues) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43368, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Yconso.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des variables d'entrée du modèle prédictif \n",
    "\n",
    "**Attention : Les données présentes dans Xinput sont encryptées dans un fichier zip.**  \n",
    "Pour les lire vous avez besoin d'un mot de passe qui ne peut vous être donné que dans le cadre d'un travail au sein de RTE.\n",
    "\n",
    "Sinon, la lecture se déroule comme pour le fichier Yconso.csv : transformation en datetime de la colonne *ds* et vérification des dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "password = 'FIFA_2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput_zip = os.path.join(data_folder, \"Xinput.zip\")\n",
    "# Pour travailler avec les fichiers zip, on utilise la bibliothèque **zipfile**.\n",
    "zipfile_xinput = zipfile.ZipFile(Xinput_zip)\n",
    "zipfile_xinput.setpassword(bytes(password,'utf-8'))\n",
    "Xinput = pd.read_csv(zipfile_xinput.open('Xinput.csv'),sep=\",\",engine='c',header=0)\n",
    "\n",
    "Xinput['ds'] = pd.to_datetime(Xinput['ds'],utc=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous disposez de relevés de températures en stations (voir le fichier *data/StationsMeteoRTE.csv* pour plus d'informations) ainsi que d'une température France prévue pour l'instant considéré et celle réalisée la veille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de X\n",
      "(43368, 74)\n",
      "\n",
      "Colonnes de X\n",
      "Index(['ds', 'holiday', '002_0', '002_24', '005_0', '005_24', '015_0',\n",
      "       '015_24', '027_0', '027_24', '070_0', '070_24', '110_0', '110_24',\n",
      "       '120_0', '120_24', '130_0', '130_24', '145_0', '145_24', '149_0',\n",
      "       '149_24', '156_0', '156_24', '168_0', '168_24', '180_0', '180_24',\n",
      "       '190_0', '190_24', '222_0', '222_24', '240_0', '240_24', '255_0',\n",
      "       '255_24', '260_0', '260_24', '280_0', '280_24', '299_0', '299_24',\n",
      "       '434_0', '434_24', '460_0', '460_24', '481_0', '481_24', '497_0',\n",
      "       '497_24', '510_0', '510_24', '579_0', '579_24', '588_0', '588_24',\n",
      "       '621_0', '621_24', '630_0', '630_24', '643_0', '643_24', '645_0',\n",
      "       '645_24', '650_0', '650_24', '675_0', '675_24', '690_0', '690_24',\n",
      "       '747_0', '747_24', 'Th_real_24h_avant', 'Th_prev'],\n",
      "      dtype='object')\n",
      "\n",
      "Aperçu de X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>holiday</th>\n",
       "      <th>002_0</th>\n",
       "      <th>002_24</th>\n",
       "      <th>005_0</th>\n",
       "      <th>005_24</th>\n",
       "      <th>015_0</th>\n",
       "      <th>015_24</th>\n",
       "      <th>027_0</th>\n",
       "      <th>027_24</th>\n",
       "      <th>...</th>\n",
       "      <th>650_0</th>\n",
       "      <th>650_24</th>\n",
       "      <th>675_0</th>\n",
       "      <th>675_24</th>\n",
       "      <th>690_0</th>\n",
       "      <th>690_24</th>\n",
       "      <th>747_0</th>\n",
       "      <th>747_24</th>\n",
       "      <th>Th_real_24h_avant</th>\n",
       "      <th>Th_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-08 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.69</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.69</td>\n",
       "      <td>9.30</td>\n",
       "      <td>10.19</td>\n",
       "      <td>10.50</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.90</td>\n",
       "      <td>5.60</td>\n",
       "      <td>10.60</td>\n",
       "      <td>8.50</td>\n",
       "      <td>9.50</td>\n",
       "      <td>10.7</td>\n",
       "      <td>11.20</td>\n",
       "      <td>9.846930</td>\n",
       "      <td>9.911160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-08 01:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.10</td>\n",
       "      <td>9.40</td>\n",
       "      <td>9.69</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.40</td>\n",
       "      <td>9.30</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.30</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.50</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10.10</td>\n",
       "      <td>8.40</td>\n",
       "      <td>9.40</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.10</td>\n",
       "      <td>9.848500</td>\n",
       "      <td>9.790830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-08 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.40</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>12.30</td>\n",
       "      <td>4.40</td>\n",
       "      <td>9.60</td>\n",
       "      <td>7.90</td>\n",
       "      <td>9.30</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9.681580</td>\n",
       "      <td>9.634990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-08 03:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.19</td>\n",
       "      <td>10.19</td>\n",
       "      <td>9.80</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>12.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>7.50</td>\n",
       "      <td>9.30</td>\n",
       "      <td>11.1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>9.487130</td>\n",
       "      <td>9.445360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-08 04:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.90</td>\n",
       "      <td>8.80</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.90</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.19</td>\n",
       "      <td>9.60</td>\n",
       "      <td>...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.80</td>\n",
       "      <td>7.30</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.490410</td>\n",
       "      <td>9.241585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2014-01-08 05:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.69</td>\n",
       "      <td>9.40</td>\n",
       "      <td>9.40</td>\n",
       "      <td>9.10</td>\n",
       "      <td>9.30</td>\n",
       "      <td>9.40</td>\n",
       "      <td>10.10</td>\n",
       "      <td>9.50</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.80</td>\n",
       "      <td>7.20</td>\n",
       "      <td>9.60</td>\n",
       "      <td>10.6</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.346880</td>\n",
       "      <td>9.045105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2014-01-08 06:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.60</td>\n",
       "      <td>8.90</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.10</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.50</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9</td>\n",
       "      <td>11.60</td>\n",
       "      <td>4.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>7.20</td>\n",
       "      <td>9.40</td>\n",
       "      <td>10.5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.284855</td>\n",
       "      <td>8.915265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2014-01-08 07:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.50</td>\n",
       "      <td>9.50</td>\n",
       "      <td>8.60</td>\n",
       "      <td>9.19</td>\n",
       "      <td>9.50</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.60</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9</td>\n",
       "      <td>12.10</td>\n",
       "      <td>5.09</td>\n",
       "      <td>8.90</td>\n",
       "      <td>7.40</td>\n",
       "      <td>9.69</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.50</td>\n",
       "      <td>9.377060</td>\n",
       "      <td>8.964100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2014-01-08 08:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.40</td>\n",
       "      <td>9.19</td>\n",
       "      <td>8.60</td>\n",
       "      <td>9.30</td>\n",
       "      <td>9.50</td>\n",
       "      <td>10.70</td>\n",
       "      <td>9.50</td>\n",
       "      <td>...</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.50</td>\n",
       "      <td>5.80</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8.00</td>\n",
       "      <td>9.60</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.543030</td>\n",
       "      <td>9.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2014-01-08 09:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.40</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.10</td>\n",
       "      <td>9.69</td>\n",
       "      <td>9.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.60</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>13.00</td>\n",
       "      <td>6.60</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>9.90</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.109460</td>\n",
       "      <td>9.630050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2014-01-08 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.40</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>9.69</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.69</td>\n",
       "      <td>11.60</td>\n",
       "      <td>9.90</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1</td>\n",
       "      <td>13.80</td>\n",
       "      <td>7.40</td>\n",
       "      <td>10.90</td>\n",
       "      <td>9.30</td>\n",
       "      <td>10.80</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>11.010330</td>\n",
       "      <td>10.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2014-01-08 11:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.40</td>\n",
       "      <td>11.80</td>\n",
       "      <td>10.60</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.60</td>\n",
       "      <td>11.60</td>\n",
       "      <td>10.40</td>\n",
       "      <td>...</td>\n",
       "      <td>13.9</td>\n",
       "      <td>14.60</td>\n",
       "      <td>9.00</td>\n",
       "      <td>11.70</td>\n",
       "      <td>10.30</td>\n",
       "      <td>11.90</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.087900</td>\n",
       "      <td>11.583100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2014-01-08 12:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.60</td>\n",
       "      <td>9.80</td>\n",
       "      <td>12.60</td>\n",
       "      <td>11.30</td>\n",
       "      <td>11.80</td>\n",
       "      <td>11.20</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.20</td>\n",
       "      <td>9.40</td>\n",
       "      <td>12.80</td>\n",
       "      <td>11.10</td>\n",
       "      <td>12.80</td>\n",
       "      <td>13.3</td>\n",
       "      <td>12.90</td>\n",
       "      <td>12.750200</td>\n",
       "      <td>12.571250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2014-01-08 13:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.90</td>\n",
       "      <td>10.00</td>\n",
       "      <td>12.60</td>\n",
       "      <td>11.40</td>\n",
       "      <td>12.80</td>\n",
       "      <td>11.30</td>\n",
       "      <td>12.80</td>\n",
       "      <td>11.30</td>\n",
       "      <td>...</td>\n",
       "      <td>15.2</td>\n",
       "      <td>15.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>13.80</td>\n",
       "      <td>12.70</td>\n",
       "      <td>13.30</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.30</td>\n",
       "      <td>13.010425</td>\n",
       "      <td>13.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2014-01-08 14:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.20</td>\n",
       "      <td>9.90</td>\n",
       "      <td>12.60</td>\n",
       "      <td>11.30</td>\n",
       "      <td>12.70</td>\n",
       "      <td>11.20</td>\n",
       "      <td>12.90</td>\n",
       "      <td>11.40</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4</td>\n",
       "      <td>15.40</td>\n",
       "      <td>10.40</td>\n",
       "      <td>14.30</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.1</td>\n",
       "      <td>13.40</td>\n",
       "      <td>13.034650</td>\n",
       "      <td>13.415650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2014-01-08 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.30</td>\n",
       "      <td>9.69</td>\n",
       "      <td>12.80</td>\n",
       "      <td>11.10</td>\n",
       "      <td>12.20</td>\n",
       "      <td>10.90</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3</td>\n",
       "      <td>14.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>14.10</td>\n",
       "      <td>13.10</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.9</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.795650</td>\n",
       "      <td>13.190725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2014-01-08 16:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.10</td>\n",
       "      <td>9.69</td>\n",
       "      <td>11.90</td>\n",
       "      <td>10.90</td>\n",
       "      <td>11.40</td>\n",
       "      <td>10.80</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.30</td>\n",
       "      <td>...</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.90</td>\n",
       "      <td>10.70</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.50</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.90</td>\n",
       "      <td>12.026650</td>\n",
       "      <td>12.621550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2014-01-08 17:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.50</td>\n",
       "      <td>11.50</td>\n",
       "      <td>10.70</td>\n",
       "      <td>11.10</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.30</td>\n",
       "      <td>11.20</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7</td>\n",
       "      <td>12.90</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.90</td>\n",
       "      <td>12.10</td>\n",
       "      <td>11.40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.40</td>\n",
       "      <td>11.561000</td>\n",
       "      <td>11.866250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2014-01-08 18:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.60</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.60</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.40</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.10</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.30</td>\n",
       "      <td>11.50</td>\n",
       "      <td>10.80</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.147930</td>\n",
       "      <td>11.217425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2014-01-08 19:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.90</td>\n",
       "      <td>10.60</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.60</td>\n",
       "      <td>11.10</td>\n",
       "      <td>...</td>\n",
       "      <td>12.4</td>\n",
       "      <td>11.50</td>\n",
       "      <td>10.30</td>\n",
       "      <td>8.40</td>\n",
       "      <td>10.90</td>\n",
       "      <td>10.50</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.70</td>\n",
       "      <td>10.985900</td>\n",
       "      <td>10.803830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2014-01-08 20:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.80</td>\n",
       "      <td>11.20</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>11.30</td>\n",
       "      <td>10.40</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.19</td>\n",
       "      <td>11.9</td>\n",
       "      <td>11.30</td>\n",
       "      <td>10.737580</td>\n",
       "      <td>10.580990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2014-01-08 21:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.19</td>\n",
       "      <td>9.69</td>\n",
       "      <td>10.70</td>\n",
       "      <td>9.60</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.10</td>\n",
       "      <td>11.30</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>11.10</td>\n",
       "      <td>10.60</td>\n",
       "      <td>7.90</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.19</td>\n",
       "      <td>11.9</td>\n",
       "      <td>11.30</td>\n",
       "      <td>10.566275</td>\n",
       "      <td>10.462200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2014-01-08 22:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.50</td>\n",
       "      <td>10.19</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.80</td>\n",
       "      <td>...</td>\n",
       "      <td>12.7</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.50</td>\n",
       "      <td>6.90</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.10</td>\n",
       "      <td>11.9</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.689410</td>\n",
       "      <td>10.114050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2014-01-08 23:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.40</td>\n",
       "      <td>11.10</td>\n",
       "      <td>9.80</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.90</td>\n",
       "      <td>11.10</td>\n",
       "      <td>...</td>\n",
       "      <td>11.8</td>\n",
       "      <td>10.90</td>\n",
       "      <td>9.90</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.6</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.505480</td>\n",
       "      <td>9.971110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2014-01-09 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.80</td>\n",
       "      <td>11.40</td>\n",
       "      <td>10.90</td>\n",
       "      <td>11.30</td>\n",
       "      <td>9.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.80</td>\n",
       "      <td>11.30</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>10.70</td>\n",
       "      <td>8.60</td>\n",
       "      <td>6.50</td>\n",
       "      <td>10.50</td>\n",
       "      <td>9.80</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.467205</td>\n",
       "      <td>9.898510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2014-01-09 01:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.30</td>\n",
       "      <td>11.60</td>\n",
       "      <td>8.50</td>\n",
       "      <td>11.40</td>\n",
       "      <td>10.50</td>\n",
       "      <td>10.90</td>\n",
       "      <td>9.19</td>\n",
       "      <td>11.30</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>10.50</td>\n",
       "      <td>7.10</td>\n",
       "      <td>6.20</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.69</td>\n",
       "      <td>11.1</td>\n",
       "      <td>9.80</td>\n",
       "      <td>10.349260</td>\n",
       "      <td>9.818325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2014-01-09 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.19</td>\n",
       "      <td>11.70</td>\n",
       "      <td>8.69</td>\n",
       "      <td>11.50</td>\n",
       "      <td>9.80</td>\n",
       "      <td>11.20</td>\n",
       "      <td>8.50</td>\n",
       "      <td>11.30</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>10.19</td>\n",
       "      <td>6.80</td>\n",
       "      <td>5.90</td>\n",
       "      <td>10.10</td>\n",
       "      <td>9.60</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.845505</td>\n",
       "      <td>9.767930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2014-01-09 03:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.50</td>\n",
       "      <td>11.90</td>\n",
       "      <td>8.80</td>\n",
       "      <td>11.60</td>\n",
       "      <td>8.80</td>\n",
       "      <td>11.30</td>\n",
       "      <td>7.80</td>\n",
       "      <td>11.20</td>\n",
       "      <td>...</td>\n",
       "      <td>11.2</td>\n",
       "      <td>9.90</td>\n",
       "      <td>7.70</td>\n",
       "      <td>5.40</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.40</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9.40</td>\n",
       "      <td>9.318530</td>\n",
       "      <td>9.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2014-01-09 04:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.60</td>\n",
       "      <td>12.00</td>\n",
       "      <td>8.10</td>\n",
       "      <td>11.70</td>\n",
       "      <td>8.80</td>\n",
       "      <td>11.40</td>\n",
       "      <td>7.50</td>\n",
       "      <td>11.10</td>\n",
       "      <td>...</td>\n",
       "      <td>11.6</td>\n",
       "      <td>9.30</td>\n",
       "      <td>7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.10</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.032335</td>\n",
       "      <td>9.544690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2014-01-09 05:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.80</td>\n",
       "      <td>10.60</td>\n",
       "      <td>8.50</td>\n",
       "      <td>10.19</td>\n",
       "      <td>8.90</td>\n",
       "      <td>10.10</td>\n",
       "      <td>6.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>7.50</td>\n",
       "      <td>5.30</td>\n",
       "      <td>9.50</td>\n",
       "      <td>8.19</td>\n",
       "      <td>11.2</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8.754755</td>\n",
       "      <td>9.081040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2014-01-09 06:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.50</td>\n",
       "      <td>10.60</td>\n",
       "      <td>7.40</td>\n",
       "      <td>10.40</td>\n",
       "      <td>9.10</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9</td>\n",
       "      <td>9.40</td>\n",
       "      <td>7.30</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>11.3</td>\n",
       "      <td>8.80</td>\n",
       "      <td>8.498830</td>\n",
       "      <td>9.003155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2014-01-09 07:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.40</td>\n",
       "      <td>11.10</td>\n",
       "      <td>7.00</td>\n",
       "      <td>10.70</td>\n",
       "      <td>8.80</td>\n",
       "      <td>10.30</td>\n",
       "      <td>6.40</td>\n",
       "      <td>10.50</td>\n",
       "      <td>...</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.30</td>\n",
       "      <td>8.69</td>\n",
       "      <td>7.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>8.248040</td>\n",
       "      <td>9.174785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2014-01-09 08:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.10</td>\n",
       "      <td>11.30</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.90</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.50</td>\n",
       "      <td>6.50</td>\n",
       "      <td>10.30</td>\n",
       "      <td>...</td>\n",
       "      <td>11.6</td>\n",
       "      <td>10.60</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.00</td>\n",
       "      <td>11.3</td>\n",
       "      <td>8.69</td>\n",
       "      <td>8.328750</td>\n",
       "      <td>9.354920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2014-01-09 09:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.80</td>\n",
       "      <td>11.30</td>\n",
       "      <td>7.10</td>\n",
       "      <td>11.10</td>\n",
       "      <td>8.40</td>\n",
       "      <td>10.80</td>\n",
       "      <td>7.60</td>\n",
       "      <td>10.19</td>\n",
       "      <td>...</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.40</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.19</td>\n",
       "      <td>9.19</td>\n",
       "      <td>8.80</td>\n",
       "      <td>11.9</td>\n",
       "      <td>9.40</td>\n",
       "      <td>9.106245</td>\n",
       "      <td>9.821385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2014-01-09 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.90</td>\n",
       "      <td>10.10</td>\n",
       "      <td>8.40</td>\n",
       "      <td>11.30</td>\n",
       "      <td>9.40</td>\n",
       "      <td>11.20</td>\n",
       "      <td>8.69</td>\n",
       "      <td>9.90</td>\n",
       "      <td>...</td>\n",
       "      <td>13.4</td>\n",
       "      <td>12.40</td>\n",
       "      <td>8.80</td>\n",
       "      <td>9.69</td>\n",
       "      <td>10.60</td>\n",
       "      <td>10.50</td>\n",
       "      <td>12.8</td>\n",
       "      <td>10.60</td>\n",
       "      <td>10.405815</td>\n",
       "      <td>10.340305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ds holiday  002_0  002_24  005_0  005_24  015_0  \\\n",
       "0  2014-01-08 00:00:00+00:00     NaN  10.30    9.69  10.00    9.80   9.69   \n",
       "1  2014-01-08 01:00:00+00:00     NaN  10.10    9.40   9.69    9.80   9.40   \n",
       "2  2014-01-08 02:00:00+00:00     NaN  10.00    9.19   9.90    9.60   9.19   \n",
       "3  2014-01-08 03:00:00+00:00     NaN   9.90    9.00   9.50    9.19   9.19   \n",
       "4  2014-01-08 04:00:00+00:00     NaN   9.90    8.80   9.00    8.90   8.90   \n",
       "5  2014-01-08 05:00:00+00:00     NaN   9.69    9.40   9.40    9.10   9.30   \n",
       "6  2014-01-08 06:00:00+00:00     NaN   9.60    9.19   9.60    8.90   9.19   \n",
       "7  2014-01-08 07:00:00+00:00     NaN   9.60    9.50   9.50    8.60   9.19   \n",
       "8  2014-01-08 08:00:00+00:00     NaN   9.90    9.40   9.19    8.60   9.30   \n",
       "9  2014-01-08 09:00:00+00:00     NaN  10.00    9.40  10.00    9.10   9.69   \n",
       "10 2014-01-08 10:00:00+00:00     NaN  10.40    9.00  10.00    9.69  10.30   \n",
       "11 2014-01-08 11:00:00+00:00     NaN  10.50    9.40  11.80   10.60  10.70   \n",
       "12 2014-01-08 12:00:00+00:00     NaN  10.60    9.80  12.60   11.30  11.80   \n",
       "13 2014-01-08 13:00:00+00:00     NaN  10.90   10.00  12.60   11.40  12.80   \n",
       "14 2014-01-08 14:00:00+00:00     NaN  11.20    9.90  12.60   11.30  12.70   \n",
       "15 2014-01-08 15:00:00+00:00     NaN  11.30    9.69  12.80   11.10  12.20   \n",
       "16 2014-01-08 16:00:00+00:00     NaN  11.10    9.69  11.90   10.90  11.40   \n",
       "17 2014-01-08 17:00:00+00:00     NaN  10.50    9.50  11.50   10.70  11.10   \n",
       "18 2014-01-08 18:00:00+00:00     NaN  10.80    9.60  10.80   10.60  10.80   \n",
       "19 2014-01-08 19:00:00+00:00     NaN  11.00    9.80   9.90   10.60  10.40   \n",
       "20 2014-01-08 20:00:00+00:00     NaN  10.80   10.00  10.10   10.80  10.10   \n",
       "21 2014-01-08 21:00:00+00:00     NaN  10.40   10.19   9.69   10.70   9.60   \n",
       "22 2014-01-08 22:00:00+00:00     NaN  10.10   10.70  10.30   10.80   9.50   \n",
       "23 2014-01-08 23:00:00+00:00     NaN   9.50   11.00  10.40   11.10   9.80   \n",
       "24 2014-01-09 00:00:00+00:00     NaN   8.80   11.40  10.90   11.30   9.80   \n",
       "25 2014-01-09 01:00:00+00:00     NaN   8.30   11.60   8.50   11.40  10.50   \n",
       "26 2014-01-09 02:00:00+00:00     NaN   9.19   11.70   8.69   11.50   9.80   \n",
       "27 2014-01-09 03:00:00+00:00     NaN   9.50   11.90   8.80   11.60   8.80   \n",
       "28 2014-01-09 04:00:00+00:00     NaN   9.60   12.00   8.10   11.70   8.80   \n",
       "29 2014-01-09 05:00:00+00:00     NaN   9.80   10.60   8.50   10.19   8.90   \n",
       "30 2014-01-09 06:00:00+00:00     NaN   9.50   10.60   7.40   10.40   9.10   \n",
       "31 2014-01-09 07:00:00+00:00     NaN   9.40   11.10   7.00   10.70   8.80   \n",
       "32 2014-01-09 08:00:00+00:00     NaN   9.10   11.30   6.80   10.90   8.19   \n",
       "33 2014-01-09 09:00:00+00:00     NaN   8.80   11.30   7.10   11.10   8.40   \n",
       "34 2014-01-09 10:00:00+00:00     NaN   8.90   10.10   8.40   11.30   9.40   \n",
       "\n",
       "    015_24  027_0  027_24  ...  650_0  650_24  675_0  675_24  690_0  690_24  \\\n",
       "0     9.30  10.19   10.50  ...   10.8   12.90   5.60   10.60   8.50    9.50   \n",
       "1     9.30  10.30   10.30  ...   10.8   12.50   4.00   10.10   8.40    9.40   \n",
       "2     9.40  10.30   10.00  ...   10.6   12.30   4.40    9.60   7.90    9.30   \n",
       "3     9.19  10.19    9.80  ...    9.8   12.00   4.00    9.10   7.50    9.30   \n",
       "4     9.00  10.19    9.60  ...   11.1   11.80   3.00    8.80   7.30    9.00   \n",
       "5     9.40  10.10    9.50  ...   11.0   11.50   3.40    8.80   7.20    9.60   \n",
       "6     9.10  10.30    9.50  ...   11.9   11.60   4.50    8.90   7.20    9.40   \n",
       "7     9.50  10.50    9.60  ...   11.9   12.10   5.09    8.90   7.40    9.69   \n",
       "8     9.50  10.70    9.50  ...   12.1   12.50   5.80    9.40   8.00    9.60   \n",
       "9     9.80  10.80    9.60  ...   12.6   13.00   6.60   10.00   8.50    9.90   \n",
       "10    9.69  11.60    9.90  ...   13.1   13.80   7.40   10.90   9.30   10.80   \n",
       "11   10.60  11.60   10.40  ...   13.9   14.60   9.00   11.70  10.30   11.90   \n",
       "12   11.20  12.50   11.00  ...   14.5   15.20   9.40   12.80  11.10   12.80   \n",
       "13   11.30  12.80   11.30  ...   15.2   15.50  10.00   13.80  12.70   13.30   \n",
       "14   11.20  12.90   11.40  ...   14.4   15.40  10.40   14.30  13.10   13.40   \n",
       "15   10.90  12.50   11.50  ...   14.3   14.80  10.80   14.10  13.10   13.00   \n",
       "16   10.80  11.50   11.30  ...   13.8   13.90  10.70   12.80  12.50   12.40   \n",
       "17   10.50  10.30   11.20  ...   13.7   12.90  10.30   10.90  12.10   11.40   \n",
       "18   10.40  11.00   11.10  ...   13.0   12.00  10.30    9.30  11.50   10.80   \n",
       "19   10.30  10.60   11.10  ...   12.4   11.50  10.30    8.40  10.90   10.50   \n",
       "20   10.30  10.80   11.20  ...   12.6   11.30  10.40    8.00  10.80   10.19   \n",
       "21   10.40  10.10   11.30  ...   12.5   11.10  10.60    7.90  10.70   10.19   \n",
       "22   10.19  10.40   10.80  ...   12.7   11.00  10.50    6.90  10.40   10.10   \n",
       "23   10.50   9.90   11.10  ...   11.8   10.90   9.90    6.80  10.50   10.00   \n",
       "24   10.80   9.80   11.30  ...   12.3   10.70   8.60    6.50  10.50    9.80   \n",
       "25   10.90   9.19   11.30  ...   12.3   10.50   7.10    6.20  10.30    9.69   \n",
       "26   11.20   8.50   11.30  ...   12.3   10.19   6.80    5.90  10.10    9.60   \n",
       "27   11.30   7.80   11.20  ...   11.2    9.90   7.70    5.40   9.90    9.40   \n",
       "28   11.40   7.50   11.10  ...   11.6    9.30   7.40    5.00   9.80    9.10   \n",
       "29   10.10   6.50   11.00  ...   11.0    9.40   7.50    5.30   9.50    8.19   \n",
       "30   10.00   6.00   11.00  ...   10.9    9.40   7.30    5.50   9.00    8.00   \n",
       "31   10.30   6.40   10.50  ...   11.3   10.00   7.60    6.30   8.69    7.60   \n",
       "32   10.50   6.50   10.30  ...   11.6   10.60   7.80    7.00   8.90    8.00   \n",
       "33   10.80   7.60   10.19  ...   12.2   11.40   8.10    8.19   9.19    8.80   \n",
       "34   11.20   8.69    9.90  ...   13.4   12.40   8.80    9.69  10.60   10.50   \n",
       "\n",
       "    747_0  747_24  Th_real_24h_avant    Th_prev  \n",
       "0    10.7   11.20           9.846930   9.911160  \n",
       "1    11.0   11.10           9.848500   9.790830  \n",
       "2    11.6   11.00           9.681580   9.634990  \n",
       "3    11.1   10.90           9.487130   9.445360  \n",
       "4    10.8   10.80           9.490410   9.241585  \n",
       "5    10.6    9.19           9.346880   9.045105  \n",
       "6    10.5    9.00           9.284855   8.915265  \n",
       "7    10.3    9.50           9.377060   8.964100  \n",
       "8    10.3    9.90           9.543030   9.106500  \n",
       "9    11.0   10.70          10.109460   9.630050  \n",
       "10   12.0   10.80          11.010330  10.447800  \n",
       "11   12.9   12.00          12.087900  11.583100  \n",
       "12   13.3   12.90          12.750200  12.571250  \n",
       "13   13.2   13.30          13.010425  13.199100  \n",
       "14   13.1   13.40          13.034650  13.415650  \n",
       "15   12.9   13.10          12.795650  13.190725  \n",
       "16   12.7   12.90          12.026650  12.621550  \n",
       "17   12.3   12.40          11.561000  11.866250  \n",
       "18   12.0   12.00          11.147930  11.217425  \n",
       "19   11.8   11.70          10.985900  10.803830  \n",
       "20   11.9   11.30          10.737580  10.580990  \n",
       "21   11.9   11.30          10.566275  10.462200  \n",
       "22   11.9   10.30          10.689410  10.114050  \n",
       "23   11.6   10.10          10.505480   9.971110  \n",
       "24   11.3   10.00          10.467205   9.898510  \n",
       "25   11.1    9.80          10.349260   9.818325  \n",
       "26   11.3    9.60           9.845505   9.767930  \n",
       "27   11.4    9.40           9.318530   9.677900  \n",
       "28   11.3    9.00           9.032335   9.544690  \n",
       "29   11.2    9.10           8.754755   9.081040  \n",
       "30   11.3    8.80           8.498830   9.003155  \n",
       "31   11.0    8.40           8.248040   9.174785  \n",
       "32   11.3    8.69           8.328750   9.354920  \n",
       "33   11.9    9.40           9.106245   9.821385  \n",
       "34   12.8   10.60          10.405815  10.340305  \n",
       "\n",
       "[35 rows x 74 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Dimensions de X\")\n",
    "print(Xinput.shape)\n",
    "print(\"\")\n",
    "print(\"Colonnes de X\")\n",
    "print(Xinput.columns)\n",
    "print(\"\")\n",
    "print(\"Aperçu de X\")\n",
    "display(Xinput.head(35))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette étude de cas, par soucis de simplicité, nous allons travailler uniquement avec des\n",
    "**températures France**. Utiliser les températures des différentes stations météo serait une piste\n",
    "intéressante pour améliorer le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput = Xinput[['ds', 'holiday', 'Th_real_24h_avant', 'Th_prev']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "    \n",
    "* Quelles sont les variables disponibles (dans Xinput et Yconso)?\n",
    "    \n",
    "* Quelles sont les dimensions (nombre d’observations et de variables) de Xinput et Yconso après lecture des fichiers csv? Est-ce cohérent?\n",
    "\n",
    "* Les données présentes dans Xinput vous semblent-elles pertinentes pour prédire la consommation nationale présente dans Yconso ?\n",
    "\n",
    "* Que pensez-vous de cette notion de \"Température France\"?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation des données \n",
    "\n",
    "La DataScience et le Machine Learning supposent de bien appréhender les données sur lesquelles nos modèles vont être entrainés. Pour cela, il est utile de faire des statistiques descriptives et des visualisations de nos différentes variables.\n",
    "\n",
    "Traitant d'un problème de prévision, on visualisera en particulier des séries temporelles.\n",
    "\n",
    "Dans les slides d'introduction, vous allez voir des :\n",
    "- échantillons de données\n",
    "- profils de courbe de consommation journaliers et saisonniers\n",
    "- visualisations de corrélation entre conso J et conso retardée\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outils de construction de modèle\n",
    "<img src=\"pictures/etabli.jpg\"  width=500 height=60>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction des jeux d'entrainement et de test\n",
    "\n",
    "Pour éviter de construire un modèle qui apprend \"par coeur\" sur ses données, et qui disposerait alors d'une capacité de généralisation faible, il est d'usage courant de disposer de plusieurs jeux de données (de caractéristiques similaires). Le minimum est de construire \n",
    "\n",
    "* un jeu d'entraînement, sur lequel on estime le modèle, \n",
    "\n",
    "* un jeu de test, jamais vu durant l'entraînement, sur lequel on va évaluer le modèle. \n",
    "\n",
    "Rapidement dit : un bon modèle est un modèle dont la capacité prédictive ne se dégrade pas trop sur le jeu test.\n",
    "\n",
    "Pour cela, on crée la fonction *prepareDataSetEntrainementTest* qui va permettre de couper Y et Xinput en deux parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataSetEntrainementTest(Xinput, Yconso, dateDebut, dateRupture, nbJourlagRegresseur=0):\n",
    "    \n",
    "    dateStart = Xinput.iloc[0]['ds']\n",
    "    \n",
    "    DateStartWithLag = dateStart + pd.Timedelta(str(nbJourlagRegresseur)+' days')  #si un a un regresseur avec du lag, il faut prendre en compte ce lag et commencer l'entrainement a la date de debut des donnees+ce lag\n",
    "    XinputTest = Xinput[(Xinput.ds >= dateRupture)]    \n",
    "\n",
    "    XinputTrain=Xinput[(Xinput.ds < dateRupture) & (Xinput.ds > DateStartWithLag) & (Xinput.ds > dateDebut)]\n",
    "    YconsoTrain=Yconso[(Yconso.ds < dateRupture) & (Yconso.ds > DateStartWithLag) & (Yconso.ds > dateDebut)]\n",
    "    YconsoTest=Yconso[(Xinput.ds >= dateRupture)]\n",
    "    \n",
    "    return XinputTrain, XinputTest, YconsoTrain, YconsoTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons la fonction modelError qui va calculer pour un échantillon (Y, Y_hat) différents scores :\n",
    "- erreur relative moyenne (MAPE en %)\n",
    "- erreur relative max (en %)\n",
    "- RMSE (en MW)\n",
    "\n",
    "Cette fonction est ensuite utilisée par les fonctions *evaluation* et *evaluation_par* qui nous permettront d'évaluer nos modèles.\n",
    "\n",
    "<img src=\"pictures/evaluation.jpg\"  width=250 height=30>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelError(Y, Yhat):\n",
    "\n",
    "    Y = Y.reset_index(drop=True)\n",
    "    \n",
    "    relativeErrorsTest = np.abs((Y['y'] - Yhat) /Y['y']) \n",
    "    errorMean = np.mean(relativeErrorsTest)\n",
    "    errorMax = np.max(relativeErrorsTest)\n",
    "    rmse = np.sqrt(mean_squared_error(Y['y'], Yhat))\n",
    "   \n",
    "    return relativeErrorsTest, errorMean, errorMax, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(YTrain, YTest, YTrainHat, YTestHat):\n",
    "    # Ytrain et Ytest ont deux colonnes : ds et y\n",
    "    # YtrainHat et YTestHat sont des vecteurs\n",
    "    ErreursTest, ErreurMoyenneTest, ErreurMaxTest, RMSETest = modelError(YTest, YTestHat)\n",
    "    print(\"l'erreur relative moyenne de test est de:\" + str(round(ErreurMoyenneTest*100,1))+\"%\")\n",
    "    print(\"l'erreur relative max de test est de:\" + str(round(ErreurMaxTest*100,1)) +\"%\")\n",
    "    print('le rmse de test est de:' + str(round(RMSETest,0)))\n",
    "    print()\n",
    "    ErreursTest, ErreurMoyenneTest, ErreurMaxTest, RMSETest = modelError(YTrain, YTrainHat)\n",
    "    print(\"l'erreur relative moyenne de train est de:\" + str(round(ErreurMoyenneTest*100,1))+\"%\")\n",
    "    print(\"l'erreur relative max de train est de:\" + str(round(ErreurMaxTest*100,1)) +\"%\")\n",
    "    print('le rmse de test est de:' + str(round(RMSETest,0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_par(X, Y, Yhat,avecJF=True):\n",
    "    Ytmp = Y\n",
    "    Ytmp['weekday'] = Ytmp.ds.dt.weekday\n",
    "    Ytmp['hour'] = Ytmp.ds.dt.hour\n",
    "    if(avecJF):\n",
    "        Ytmp['JoursFeries'] = X['JoursFeries']\n",
    "    Ytmp['APE'] = np.abs(Ytmp['y']-Yhat)/Ytmp['y']\n",
    "    dataWD = Ytmp[['weekday','APE']]\n",
    "    groupedWD = dataWD.groupby(['weekday'], as_index=True)\n",
    "    statsWD = groupedWD.aggregate([np.mean])\n",
    "    dataHour = Ytmp[['hour','APE']]\n",
    "    groupedHour = dataHour.groupby(['hour'], as_index=True)\n",
    "    statsHour = groupedHour.aggregate([np.mean])\n",
    "    \n",
    "    if(avecJF):\n",
    "        dataJF = Ytmp[['JoursFeries','APE']]\n",
    "        groupedJF = dataJF.groupby(['JoursFeries'], as_index=True)\n",
    "        statsJF = groupedJF.aggregate([np.mean])\n",
    "    else:\n",
    "        statsJF = None\n",
    "    \n",
    "    return statsWD, statsHour, statsJF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering : préparation de Xinput\n",
    "\n",
    "L'objectif de cette partie est d'enrichir Xinput à partir des données initiales. Il s'agit notamment d'exploiter les différentes informations calendaires disponibles.\n",
    "\n",
    "Dans un premier temps, on supprime la consommation retardée d'une heure, non disponible pour notre exercice de prévision J+1.\n",
    "Et on vérifie le travail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput = Xinput.drop(['lag1H'],axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xinput.shape)\n",
    "print(Xinput.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on encode les données calendaires en one-hot encoding pour le modèle. Autrement dit, on construit pour chaque modalité, une variable binaire associée.\n",
    "Cet encodage est nécessaire pour que le modèle mathématique puisse appréhender la notion de date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedWeekDay = pd.get_dummies(Xinput['weekday'],prefix=\"weekday\")\n",
    "encodedMonth = pd.get_dummies(Xinput['month'],prefix=\"month\")\n",
    "encodedHour = pd.get_dummies(Xinput['hour'],prefix=\"hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedWeekDay.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedMonth.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedHour.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput = pd.concat([Xinput, encodedMonth, encodedWeekDay, encodedHour], axis=1)\n",
    "Xinput = Xinput.drop(['month','weekday','hour'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xinput.shape)\n",
    "print(Xinput.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les données météo, on récupère aussi la prévision effectuée pour la veille. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToKeepWeather = [s for s in Xinput.columns.get_values() if 'Th_prev' in s]\n",
    "lag_colsToKeepWeather = [ s + \"_J_1\" for s in colsToKeepWeather ]\n",
    "Xinput[lag_colsToKeepWeather] = Xinput[colsToKeepWeather].shift(24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère aussi le jour de l'année grâce à la fonction *dayofyear*, ainsi que les jours fériés. On crée une variable binaire associée à chaque jour férié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Récupération des jours fériés dans Xinput\n",
    "time = pd.to_datetime(Xinput['ds'], yearfirst=True,utc=True)\n",
    "Xinput['posan']= time.dt.dayofyear\n",
    "encodedHolidays = pd.get_dummies(Xinput[['holiday']], prefix = \"JF\")\n",
    "encodedHolidays['JoursFeries'] = encodedHolidays.sum(axis = 1)\n",
    "Xinput = pd.concat([Xinput, encodedHolidays], axis = 1)\n",
    "Xinput = Xinput.drop(['holiday'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute des températures seuillées, à 15°C pour l'effet chauffage, et à 18°C pour l'effet climatisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_temperature_heat = 15\n",
    "threshold_temperature_cool = 18\n",
    "\n",
    "Xinput['temp_prev_with_threshold_heat'] = np.maximum(0, threshold_temperature_heat - Xinput['Th_prev'].values)\n",
    "Xinput['temp_prev_with_threshold_cool'] = np.maximum(0, Xinput['Th_prev'].values - threshold_temperature_cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#affichage de toutes les variables de base\n",
    "list(Xinput) #list plutôt que print pour avoir la liste complète"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous construisons les listes pour appeler plus rapidement les colonnes d'un même type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToKeepWeather = [s for s in Xinput.columns.get_values() if 'Th_prev' in s]\n",
    "colsToKeepMonth = [v for v in Xinput.columns.get_values() if 'month' in v]\n",
    "colsToKeepWeekday = [v for v in Xinput.columns.get_values() if 'weekday' in v]\n",
    "colsToKeepHour = [v for v in Xinput.columns.get_values() if 'hour' in v]\n",
    "colsToKeepHolidays = [v for v in Xinput.columns.get_values() if 'JF_' in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on souhaite un jeu de test qui commence à partir du 1er mai 2017\n",
    "dateDebut = pytz.utc.localize( datetime.datetime(year=2014, month=1, day=15))#pour éviter les NaN dans le jeu de données\n",
    "dateRupture = pytz.utc.localize(datetime.datetime(year=2017, month=12, day=1))#début du challenge prevision de conso\n",
    "nbJourlagRegresseur = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yconso.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XinputTrain, XinputTest, YconsoTrain, YconsoTest = prepareDataSetEntrainementTest(Xinput, Yconso, \n",
    "                                                                                  dateDebut, dateRupture, \n",
    "                                                                                  nbJourlagRegresseur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('la taille de l échantillon XinputTrain est:' + str(XinputTrain.shape))\n",
    "print('la taille de l échantillon XinputTest est:' + str(XinputTest.shape))\n",
    "print('la taille de l échantillon YconsoTrain est:' + str(YconsoTrain.shape))\n",
    "print('la taille de l échantillon YconsoTest est:' + str(YconsoTest.shape))\n",
    "print(\"la proportion de data d'entrainement est de:\" + str(YconsoTrain.shape[0] / (YconsoTrain.shape[0] + YconsoTest.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'un modèle prédictif naïf\n",
    "\n",
    "<img src=\"pictures/hommeNaif.png\" width=500 height=60>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première idée, un modèle naïf : on plaque bêtement la valeur de consommation nationale de la veille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par juste notre point horaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_modele_naif_1 = float(Xinput.loc[Xinput['ds'] == datetime_a_predire]['lag1D'])\n",
    "pred_error = abs(y_true_point_horaire_cible - y_pred_modele_naif_1)\n",
    "\n",
    "print(\"Modele 1 -- pred: {}, realisee: {}, erreur: {}%\".format(y_pred_modele_naif_1, y_true_point_horaire_cible, pred_error/y_true_point_horaire_cible * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons maintenant ce que ça donne non plus sur un unique point horaire mais sur l'ensemble des points horaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_modele_naif_1 = Xinput[\"lag1D\"]\n",
    "\n",
    "pred_error = (np.abs(Yconso[\"y\"] - y_pred_modele_naif_1.loc[24:]) / Yconso[\"y\"] * 100)\n",
    "\n",
    "print(np.mean(pred_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_train_naif1= XinputTrain[\"lag1D\"]\n",
    "pred_test_naif1= XinputTest[\"lag1D\"]\n",
    "evaluation(YconsoTrain, YconsoTest,  pred_train_naif1.values,pred_test_naif1.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon c'est pas fou..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième idée : modèle naïf avec de l'expertise métier \n",
    "\n",
    "Chez RTE, on considère qu'une augmentation moyenne de 1°C conduit à une augmentation de 2400MW de la consommation nationale pour des températures inférieures à 15°C. On propose donc comme consommation prévue la consommation de la veille, corrigée par 2400 fois l'écart à la température de la veille, si l'on n'excède pas les 15°C.\n",
    "\n",
    "\n",
    "<img src=\"pictures/ExpertJamy.jpg\" width=500 height=60>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_MW_par_degre = 2400  \n",
    "            \n",
    "threshold_temperature = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par juste notre point horaire préféré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_real_veille = float(Xinput.loc[Xinput['ds'] == datetime_a_predire]['Th_real_24h_avant'])\n",
    "temperature_prevu_cible = float(Xinput.loc[Xinput['ds'] == datetime_a_predire]['Th_prev'])\n",
    "delta_temp = min(threshold_temperature, temperature_prevu_cible) - min(threshold_temperature, temperature_real_veille)\n",
    "delta_MW_because_temp = delta_temp * delta_MW_par_degre\n",
    "\n",
    "y_pred_modele_naif_2 = float(Xinput.loc[Xinput['ds'] == datetime_a_predire]['lag1D']) - delta_MW_because_temp\n",
    "pred_error = abs(y_true_point_horaire_cible - y_pred_modele_naif_2)\n",
    "\n",
    "print(\"Modele 2 -- pred: {}, realisee: {}, erreur: {}%\".format(y_pred_modele_naif_2, y_true_point_horaire_cible, pred_error/y_true_point_horaire_cible * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant sur l'ensemble des points horaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Xinput[\"lag1D\"]\n",
    "\n",
    "temp_prev_with_threshold = np.minimum([threshold_temperature], Xinput['Th_prev'].values)\n",
    "temp_actual_with_threshold = np.minimum([threshold_temperature], Xinput['Th_real_24h_avant'].values)\n",
    "\n",
    "delta_temp = temp_prev_with_threshold - temp_actual_with_threshold\n",
    "delta_MW_because_temp = delta_temp * delta_MW_par_degre\n",
    "\n",
    "y_pred_modele_naif_2 = Xinput[\"lag1D\"] - delta_MW_because_temp\n",
    "pred_error = (np.abs(Yconso[\"y\"] - y_pred_modele_naif_2) / Yconso[\"y\"] * 100)\n",
    "\n",
    "print(np.mean(pred_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon... Bien essayé avec ces modèles naïfs, mais maintenant on va être plus sérieux !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test des fonctions sur le modèle expert\n",
    "\n",
    "Recalculons les prévisions à l'aide des deux modèles experts et évaluons ces deux approches :\n",
    "\n",
    "### Modèle naïf 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle naïf 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prévision train\n",
    "temp_prev_with_threshold = np.minimum([threshold_temperature], XinputTrain['Th_prev'].values)\n",
    "temp_actual_with_threshold = np.minimum([threshold_temperature], XinputTrain['Th_real_24h_avant'].values)\n",
    "\n",
    "delta_temp = temp_prev_with_threshold - temp_actual_with_threshold\n",
    "delta_MW_because_temp = delta_temp * delta_MW_par_degre\n",
    "\n",
    "pred_train_naif2 = XinputTrain[\"lag1D\"] - delta_MW_because_temp\n",
    "\n",
    "\n",
    "# prévision test\n",
    "temp_prev_with_threshold = np.minimum([threshold_temperature], XinputTest['Th_prev'].values)\n",
    "temp_actual_with_threshold = np.minimum([threshold_temperature], XinputTest['Th_real_24h_avant'].values)\n",
    "\n",
    "delta_temp = temp_prev_with_threshold - temp_actual_with_threshold\n",
    "delta_MW_because_temp = delta_temp * delta_MW_par_degre\n",
    "pred_test_naif2 = XinputTest[\"lag1D\"] - delta_MW_because_temp\n",
    "\n",
    "# scores\n",
    "evaluation(YconsoTrain, YconsoTest,  pred_train_naif2.values,pred_test_naif2.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Régression linéaire simple\n",
    "\n",
    "Le modèle naïf avec expertise métier a été inspiré de la forme de la courbe d'évolution de la consommation en fonction de la température en France. \n",
    "Pour rappel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xinput['Th_prev'], Yconso['y'], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La consommation pourrait être modélisée par une fonction linéaire par morceaux de la température, avec une pente plus importante pour les températures froides que pour les températures élevées. Au lieu de fixer les gradients à 2400MW/°C et 0, ceux-ci pourraient être calibrés à partir des données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainer un modèle\n",
    "Notre modèle a des paramètres qu'il va falloir maintenant apprendre au vu de notre jeu d'entrainement. Il faut donc caler notre modèle sur ce jeu d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsLR_simple = np.concatenate(([s for s in XinputTrain.columns.get_values() if 'temp_prev_with_' in s], colsToKeepHour, colsToKeepWeekday, colsToKeepMonth))\n",
    "\n",
    "mTrain = linear_model.LinearRegression(fit_intercept = False)\n",
    "mTrain.fit(XinputTrain[colsLR_simple], YconsoTrain[['y']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpréter le modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef_joli = pd.DataFrame(np.concatenate(( np.array([colsLR_simple]).T,mTrain.coef_.T),axis=1),columns = ['variable','coefficient'])\n",
    "print(coef_joli)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Commentez les coefficients de régression obtenus. \n",
    "* Comparez notamment les gradients obtenus avec le modèle naïf.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire des prédictions\n",
    "Une fois qu'un modèle de prévision est entrainé, il ne s'avère utile que s'il est performant sur de nouvelles situations. Faisons une prévision sur notre jeu de test. Traçons les courbes obtenues et calculons les scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastTest = np.concatenate(mTrain.predict(XinputTest[colsLR_simple]))\n",
    "forecastTrain = np.concatenate(mTrain.predict(XinputTrain[colsLR_simple]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(forecastTest, YconsoTest[['y']])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(YconsoTest['ds'], YconsoTest['y'], 'b', YconsoTest['ds'], forecastTest, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation(YconsoTrain, YconsoTest, forecastTrain,  forecastTest)\n",
    "evalWD,evalHour,evalJF = evaluation_par(XinputTest,YconsoTest,forecastTest,avecJF=True)\n",
    "print(str(round(evalWD*100,1)))\n",
    "print(str(round(evalHour*100,1)))\n",
    "print(str(round(evalJF*100,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment se distribue l'erreur ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erreur_relative_test, erreur_moyenne_test, erreur_max_test, rmse = modelError(YconsoTest, forecastTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 100\n",
    "plt.hist(erreur_relative_test, num_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quel moment se trompe-t-on le plus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(YconsoTest['ds'], erreur_relative_test, 'r')\n",
    "plt.title(\"erreur relative sur la periode de test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erreur_relative_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.18\n",
    "\n",
    "mask = (erreur_relative_test >= threshold)\n",
    "erreurs_df = pd.DataFrame(np.concatenate((YconsoTest[['ds','y']],np.array([forecastTest]).T),axis=1),columns=[\"date\",\"y\",\"prev\"])\n",
    "print(erreurs_df[mask])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu des résultats précédents :\n",
    "<font color= 'green'>\n",
    "\n",
    "- que pensez-vous du modèle?\n",
    "- comment se distribue l'erreur?\n",
    "- quand se trompe-t-on le plus?\n",
    "- quelles variables explicatives ajouter?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autres modèles : RandomForest et XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle RandomForest\n",
    "\n",
    "<img src=\"pictures/randomForestExplain.png\" width=500 height=30>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix des données d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsRF = np.concatenate((['lag1D','lag1W'],\n",
    "                         colsToKeepWeather,colsToKeepMonth,colsToKeepWeekday,colsToKeepHour,colsToKeepHolidays))\n",
    "list(colsRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La cellule peut prendre un peu de temps à exécuter\n",
    "print(Xinput.head(20))\n",
    "rfTrain = RandomForestRegressor(n_estimators=30, max_features=colsRF.size, n_jobs=3, oob_score = True, bootstrap = True)\n",
    "rfTrain.fit(XinputTrain[colsRF], YconsoTrain['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Grâce à l'aide de la fonction, déterminer les paramètres de cette méthode\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastTest = rfTrain.predict(XinputTest[colsRF])\n",
    "forecastTrain = rfTrain.predict(XinputTrain[colsRF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "evaluation(YconsoTrain, YconsoTest, forecastTrain, forecastTest)\n",
    "\n",
    "# on visualise nos previsions par rapport a la realité\n",
    "plt.plot(YconsoTest['ds'], YconsoTest['y'], 'b', YconsoTest['ds'], forecastTest, 'r')\n",
    "plt.show()\n",
    "\n",
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(rfTrain.score(XinputTrain[colsRF], YconsoTrain['y']), \n",
    "                                                                                             rfTrain.oob_score_,\n",
    "rfTrain.score(XinputTest[colsRF], YconsoTest['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalWD,evalHour,evalJF = evaluation_par(XinputTest,YconsoTest,forecastTest)\n",
    "print(str(round(evalWD*100,1)))\n",
    "print(str(round(evalHour*100,1)))\n",
    "print(str(round(evalJF*100,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle xgboost\n",
    "\n",
    "<img src=\"pictures/XGboost.png\" width=500 height=30>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbTrain = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "xgbTrain.fit(XinputTrain[colsRF], YconsoTrain['y'].values)\n",
    "forecastTestXGB = xgbTrain.predict(XinputTest[colsRF])\n",
    "forecastTrainXGB = xgbTrain.predict(XinputTrain[colsRF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Grâce à l'aide de la fonction, déterminer les paramètres de cette méthode\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(YconsoTrain, YconsoTest, forecastTrainXGB, forecastTestXGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalWD,evalHour,evalJF = evaluation_par(XinputTest, YconsoTest, forecastTestXGB)\n",
    "print(str(round(evalWD * 100,1)))\n",
    "print(str(round(evalHour * 100,1)))\n",
    "print(str(round(evalJF * 100,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: à vous de jouer\n",
    "\n",
    "Bravo ! Vous avez déjà créé un premier modèle performant pour faire des prévisions sur une fenêtre glissante à horizon 24h !\n",
    "\n",
    "Maintenant à vous de mettre votre expertise pour créer de nouveaux modèles.\n",
    "\n",
    "Vous pouvez continuer à explorer le problème selon plusieurs axes:\n",
    "- choix de la méthode de modélisation\n",
    "- apprendre votre modèle sur une période différente\n",
    "- créer de nouvelles variables explicatives ? Quid de la météo et de la température? Des jours fériés ? Du feature engineering plus complexe...\n",
    "- détecter des outliers dans les données\n",
    "\n",
    "Mettez-vous en 3 groupes, explorez pendant 30 minutes, et restituez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
