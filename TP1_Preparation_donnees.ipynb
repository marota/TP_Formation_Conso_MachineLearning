{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP facultatif : Préparation du jeu de données brut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand on se lance avec enthousiasme dans un nouveau projet de machine-learning, on pense avant tout au choix du modèle que l'on va utiliser. Cependant, et même s'il ne s'agit pas de l'étape la plus agréable du travail, un préalable indispensable est de réunir les données brutes et de les mettre en forme pour qu'elles puissent être ingérées par le modèle.\n",
    "\n",
    "L'objectif de ce TP est de comprendre comment, à partir de différentes sources de données, on construit nos jeux de données \"propres\" pour ensuite construire le meilleur modèle d'apprentissage possible pour la prévision de consommation nationale.\n",
    "\n",
    "Nos fichiers d'entrée bruts sont les suivants :\n",
    "> * YconsoT0.csv\n",
    "> * joursFeries.csv\n",
    "> * StationsMeteoRTE.csv  # Les coordonnées géographiques et les poids associés aux stations météos\n",
    "> * meteoX_T0_T24.zip\n",
    "> * eCO2mix_RTE_tempo_2017-2018.xls  # le sinformations sur les jours TEMPO\n",
    "\n",
    "Et les fichiers que l'on va créer sont :\n",
    "> * Xinput.csv  # Les entrées pour le modèle d'apprentissage\n",
    "> * Yconso.csv  # les sorties pour le modèle d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environnement\n",
    "\n",
    "Chargement des librairies python, et quelques éléments de configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n",
      "\n",
      "Mon repertoire de data est : D:\\Users\\montuelleluc\\Documents\\Etudes\\Formations-RTE\\MOOC IA&DeepLearning\\TP_Formation_Conso_DeepLearning\\data\n",
      "\n",
      "Fichiers contenus dans ce répertoire :\n",
      " - communes_coordonnees.csv\n",
      " - eCO2mix_RTE_tempo_2017-2018.xls\n",
      " - joursFeries.csv\n",
      " - meteoX_T0_T24.zip\n",
      " - StationsMeteoRTE.csv\n",
      " - Xinput.csv\n",
      " - Xinput.zip\n",
      " - Yconso.csv\n",
      " - YconsoT0.csv\n"
     ]
    }
   ],
   "source": [
    "# Exécutez la cellule ci-dessous (par exemple avec shift-entrée)\n",
    "# Si vous exécuter ce notebook depuis votre PC, il faudra peut-etre installer certaines librairies avec \n",
    "# 'pip3 install ma_librairie'\n",
    "import os  # accès aux commandes système\n",
    "import datetime  # structure de données pour gérer des objets calendaires\n",
    "import pandas as pd  # gérer des tables de données en python\n",
    "import numpy as np  # librairie d'opérations mathématiques\n",
    "import zipfile # manipulation de fichiers zip\n",
    "import urllib3 # téléchargement de fichier\n",
    "\n",
    "%autosave 0\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(),\"data\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Mon repertoire de data est : {}\".format(data_folder))\n",
    "print(\"\")\n",
    "print(\"Fichiers contenus dans ce répertoire :\")\n",
    "for file in os.listdir(data_folder):\n",
    "    print(\" - \" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données\n",
    "\n",
    "Dans cette partie nous allons charger les fichiers csv nécessaires pour l'analyse, puis les convertir en data-frame python. \n",
    "\n",
    "Les données de base à récupérer sont :\n",
    "- Les historiques de consommation\n",
    "- Le calendrier des jours fériés\n",
    "- Les données météo, ainsi que la liste des stations\n",
    "- Le calendrier des jours TEMPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données de consommation\n",
    "\n",
    "Dans un premier temps on importe les données de consommation réalisée à partir du fichier \"YconsoT0.csv\". La date et l'heure sont données dans les deux premières colonnes, et les autres colonnes correspondent aux consommations des 12 régions françaises (hors Corse) et à la consommation nationale.\n",
    "\n",
    "Pour cela on utilise la bibliothèque **pandas** pour la manipulation de données et la fonction **read_csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import depuis un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les données du csv sont importé dans un objet de type dataframe\n",
    "conso_csv = os.path.join(data_folder, \"YconsoT0.csv\")\n",
    "conso_df = pd.read_csv(conso_csv, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut ensuite vérifier que les données sont importées correctement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156172, 15)\n"
     ]
    }
   ],
   "source": [
    "# Afficher les dimensions et le noms des colonnes de la data frame\n",
    "print(conso_df.shape)  # Nombre de lignes, nombre de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'time', 'Consommation.PAC.t0', 'Consommation.PLO.t0',\n",
      "       'Consommation.NOR.t0', 'Consommation.NPP.t0', 'Consommation.LRM.t0',\n",
      "       'Consommation.IDF.t0', 'Consommation.CEN.t0', 'Consommation.BRE.t0',\n",
      "       'Consommation.BFC.t0', 'Consommation.ARA.t0', 'Consommation.ALP.t0',\n",
      "       'Consommation.ACA.t0', 'Consommation.NAT.t0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Liste des colonnes de la data-frama\n",
    "print(conso_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   time  Consommation.PAC.t0  Consommation.PLO.t0  \\\n",
      "0  2012-12-28  00:00                 5824                 3126   \n",
      "1  2012-12-28  00:15                 5949                 2896   \n",
      "2  2012-12-28  00:30                 6072                 2670   \n",
      "3  2012-12-28  00:45                 6193                 2446   \n",
      "4  2012-12-28  01:00                 6312                 2226   \n",
      "\n",
      "   Consommation.NOR.t0  Consommation.NPP.t0  Consommation.LRM.t0  \\\n",
      "0                 3417                 5677                 4686   \n",
      "1                 3286                 5525                 4420   \n",
      "2                 3158                 5374                 4158   \n",
      "3                 3031                 5226                 3899   \n",
      "4                 2906                 5081                 3644   \n",
      "\n",
      "   Consommation.IDF.t0  Consommation.CEN.t0  Consommation.BRE.t0  \\\n",
      "0                 8514                 2164                 2684   \n",
      "1                 8210                 2012                 2505   \n",
      "2                 7910                 1862                 2328   \n",
      "3                 7614                 1715                 2153   \n",
      "4                 7322                 1569                 1981   \n",
      "\n",
      "   Consommation.BFC.t0  Consommation.ARA.t0  Consommation.ALP.t0  \\\n",
      "0                 2222                 7718                 5381   \n",
      "1                 2156                 7495                 5340   \n",
      "2                 2091                 7275                 5300   \n",
      "3                 2026                 7059                 5261   \n",
      "4                 1963                 6845                 5222   \n",
      "\n",
      "   Consommation.ACA.t0  Consommation.NAT.t0  \n",
      "0                 4681                59679  \n",
      "1                 4552                59632  \n",
      "2                 4426                58103  \n",
      "3                 4301                56438  \n",
      "4                 4178                55354  \n"
     ]
    }
   ],
   "source": [
    "# Affichage des premières lignes\n",
    "print(conso_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Petit détour pour gérer les dates\n",
    "\n",
    "Le fichier YconsoT0.csv contient en particulier 2 colonnes 'date' et 'time'. Celles-ci contiennent des objets de type \"string\" correspondant à la date et à l'heure. \n",
    "\n",
    "<img src=\"pictures/clock.png\" width=60 height=60>\n",
    "\n",
    "Nous allons fusionner ces informations en une nouvelle colonne d'objets de type **datetime** mieux adaptés pour la manipulation de dates et d'heures. En effet, pour manipuler des dates (effectuer des tris, des sélections, récupérer si c'est un lundi, mardi,...), il est plus efficace de passer par un objet \"datetime\" plutôt que de se débrouiller en manipulant des chaînes de caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On appelle \"ds\" (dateStamp) cette nouvelle colonne\n",
    "conso_df['ds'] = pd.to_datetime(conso_df['date'] + \" \" + conso_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-28 00:00:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-28 00:15:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-28 00:30:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-28 00:45:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-28 01:00:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds        date   time\n",
       "0 2012-12-28 00:00:00  2012-12-28  00:00\n",
       "1 2012-12-28 00:15:00  2012-12-28  00:15\n",
       "2 2012-12-28 00:30:00  2012-12-28  00:30\n",
       "3 2012-12-28 00:45:00  2012-12-28  00:45\n",
       "4 2012-12-28 01:00:00  2012-12-28  01:00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conso_df[['ds', 'date', 'time']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule ci-dessous a pour but d'illustrer comment utiliser ces objets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noel_2017_date vaut : 2017-12-25, et est de type <class 'datetime.date'>\n",
      "noel_2017_str vaut : 2017-12-25, et est de type <class 'str'>\n",
      "---\n",
      "starwars_day_2017_date vaut : 2017-05-04 00:00:00, et est de type <class 'datetime.datetime'>\n",
      "D'ailleurs, c'était le 4 ème jour de la semaine, où 0 correspond à lundi et 6 correspond à dimanche\n",
      "starwars_day_2017_str vaut : 2017-05-04, et est de type <class 'str'>\n",
      "---\n",
      "Le 31 décembre 2017 plus un jour ça donne le 2018-01-01\n"
     ]
    }
   ],
   "source": [
    "# datetime vers string\n",
    "noel_2017_date = datetime.date(2017, 12, 25)\n",
    "noel_2017_str = datetime.datetime.strftime(noel_2017_date, format=\"%Y-%m-%d\")\n",
    "print(\"noel_2017_date vaut : {}, et est de type {}\".format(noel_2017_date, str(type(noel_2017_date))))\n",
    "print(\"noel_2017_str vaut : {}, et est de type {}\".format(noel_2017_str, str(type(noel_2017_str))))\n",
    "print(\"---\")\n",
    "\n",
    "# string vers datetime\n",
    "starwars_day_2017_str = \"2017-05-04\"\n",
    "starwars_day_2017_date = datetime.datetime.strptime(starwars_day_2017_str, \"%Y-%m-%d\")\n",
    "print(\"starwars_day_2017_date vaut : {}, et est de type {}\".format(starwars_day_2017_date, str(type(starwars_day_2017_date))))\n",
    "print(\"D'ailleurs, c'était le \" + str(starwars_day_2017_date.weekday() + 1) + \" ème jour de la semaine, où 0 correspond à lundi et 6 correspond à dimanche\")\n",
    "print(\"starwars_day_2017_str vaut : {}, et est de type {}\".format(starwars_day_2017_str, str(type(starwars_day_2017_str))))\n",
    "print(\"---\")\n",
    "\n",
    "# Voyager dans le temps\n",
    "saint_sylvestre_2017_date = datetime.date(2017, 12, 31)\n",
    "bienvenu_en_2018_date = saint_sylvestre_2017_date + datetime.timedelta(days=1)\n",
    "print(\"Le 31 décembre 2017 plus un jour ça donne le {}\".format(bienvenu_en_2018_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réduction du problème : se débarrasser des données qui ne nous intéressent pas\n",
    "\n",
    "Le dataframe de consommation est volumineux, et contient beaucoup d'informations inutiles (au moins en première approximation) pour notre problème de prévision de la consommation nationale. On va donc le simplifier.\n",
    "\n",
    "On va se concentrer sur la consommation à l'**échelle nationale** au **pas horaire**. On va donc ne conserver que la colonne qui nous intéresse, et ne conserver que les lignes qui correspondent aux heures pleines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on commence par ecarter les colonnes inutiles\n",
    "conso_france_df = conso_df[['ds', 'Consommation.NAT.t0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et maintenant on ne garde que les heures pleines\n",
    "# Pour cela on va utiliser notre colonne d'objet datetime\n",
    "minutes = conso_france_df['ds'].dt.minute\n",
    "indices_hours = np.where(minutes.values == 0.0)\n",
    "\n",
    "#print(conso_france_df['ds'])\n",
    "#print(minutes)\n",
    "#print(indices_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>Consommation.NAT.t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-28 00:00:00</td>\n",
       "      <td>59679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-28 01:00:00</td>\n",
       "      <td>55354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-12-28 02:00:00</td>\n",
       "      <td>54324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-12-28 03:00:00</td>\n",
       "      <td>52066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012-12-28 04:00:00</td>\n",
       "      <td>49684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ds  Consommation.NAT.t0\n",
       "0  2012-12-28 00:00:00                59679\n",
       "4  2012-12-28 01:00:00                55354\n",
       "8  2012-12-28 02:00:00                54324\n",
       "12 2012-12-28 03:00:00                52066\n",
       "16 2012-12-28 04:00:00                49684"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conso_france_horaire_df = conso_france_df.loc[indices_hours]\n",
    "conso_france_horaire_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds  Consommation.NAT.t0\n",
      "0 2012-12-28 00:00:00                59679\n",
      "1 2012-12-28 01:00:00                55354\n",
      "2 2012-12-28 02:00:00                54324\n",
      "3 2012-12-28 03:00:00                52066\n",
      "4 2012-12-28 04:00:00                49684\n",
      "(39043, 2)\n"
     ]
    }
   ],
   "source": [
    "# les index de ce sous-dataframe correspondent à celle du dataframe de base,\n",
    "# et donc sont pour l'instant des multiples de 4.\n",
    "# on va les réinitialiser pour avoir une dataframe \"neuve\"\n",
    "conso_france_horaire_df = conso_france_horaire_df.reset_index(drop=True)  \n",
    "print(conso_france_horaire_df.head(5))\n",
    "print(conso_france_horaire_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récuperation des jours fériés\n",
    "\n",
    "Même principe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>Noel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NouvelAn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>Paques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>1erMai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>8Mai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ds   holiday\n",
       "0  2012-12-25      Noel\n",
       "1  2013-01-01  NouvelAn\n",
       "2  2013-04-01    Paques\n",
       "3  2013-05-01    1erMai\n",
       "4  2013-05-08      8Mai"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jours_feries_csv = os.path.join(data_folder,\"joursFeries.csv\")\n",
    "jours_feries_df = pd.read_csv(jours_feries_csv, sep=\";\")\n",
    "\n",
    "jours_feries_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après import du csv, la colonne ds est de type <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Pour la première colonne, les dates sont au format \"string\"\n",
    "# Nous allons les convertir en objet \"datetime\" mieux adaptés pour la manipulation de dates\n",
    "print(\"Après import du csv, la colonne ds est de type \" + str(type(jours_feries_df.ds[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maintenant, la colonne ds est de type <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "jours_feries_df.ds = pd.to_datetime(jours_feries_df.ds)\n",
    "print(\"maintenant, la colonne ds est de type \" + str(type(jours_feries_df.ds[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>Noel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NouvelAn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>Paques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>1erMai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>8Mai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-05-09</td>\n",
       "      <td>Ascension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-05-20</td>\n",
       "      <td>Pentecote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-07-14</td>\n",
       "      <td>FeteNationale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds        holiday\n",
       "0 2012-12-25           Noel\n",
       "1 2013-01-01       NouvelAn\n",
       "2 2013-04-01         Paques\n",
       "3 2013-05-01         1erMai\n",
       "4 2013-05-08           8Mai\n",
       "5 2013-05-09      Ascension\n",
       "6 2013-05-20      Pentecote\n",
       "7 2013-07-14  FeteNationale"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jours_feries_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette dataframe fait correspondre le timestamp \"2012-12-25\" avec \"Noël\". Cependant, le timestamp \"2012-12-25\" correspond implicitemlent au timestamp \"2012-12-25 00:00\", ce qui fait que pour l'instant les timestamp \"2012-12-25 00:05\" ou \"2012-12-25 03:00\" ne sont pas identifiés comme étant aussi Noël, ce qui va poser problème plus tard.\n",
    "\n",
    "La cellule ci-dessous va étendre la dataframe des jours fériés de sorte à résoudre ce problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_of_interest = conso_df[['ds']]\n",
    "timestamps_of_interest[\"day\"] = timestamps_of_interest[\"ds\"].apply(lambda x: datetime.datetime.strftime(x, format=\"%Y-%m-%d\"))\n",
    "\n",
    "tmp_df = jours_feries_df\n",
    "tmp_df[\"day\"] = jours_feries_df[\"ds\"].apply(lambda x: datetime.datetime.strftime(x, format=\"%Y-%m-%d\"))\n",
    "\n",
    "tmp_df = pd.merge(timestamps_of_interest, tmp_df, on='day', how=\"left\", suffixes=(\"\", \"_tmp\"))\n",
    "\n",
    "jours_feries_df = tmp_df[[\"ds\", \"holiday\"]]\n",
    "print(jours_feries_df.loc[450:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des coordonnées géographiques des stations météo - au boulot !\n",
    "\n",
    "On va charger le csv qui à chaque station météo attribue sa longitude/latitude/poids. Pour en savoir plus sur les poids :  \n",
    "https://clients.rte-france.com/lang/fr/visiteurs/services/actualites.jsp?id=9482&mode=detail\n",
    "\n",
    "**Votre mission** :\n",
    "- Importez les données contenues dans le fichier csv *StationsMeteoRTE.csv* qui se situe dans data_folder vers un dataframe *stations_meteo_df*\n",
    "- Regardez à quoi ces données ressemblent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez les données de StationsMeteoRTE.csv vers stations_meteo_df\n",
    "stations_meteo_csv = os.path.join(data_folder, \"StationsMeteoRTE.csv\")\n",
    "stations_meteo_df = pd.read_csv(stations_meteo_csv, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_meteo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour compter le nombre de stations il suffit de compter le nombre de lignes dans le data-frame\n",
    "# Ceci se fait un utilisant \"shape\"\n",
    "nb_stations = stations_meteo_df.shape[0]\n",
    "print(nb_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération du dataframe de météo\n",
    "\n",
    "<img src=\"pictures/weather.png\" width=60 height=60>\n",
    "\n",
    "On va utiliser les mêmes fonctions que précédemment pour lire le fichier **'meteoX_T.csv'**, qui est situé dans data_folder et contient les historiques de température réalisée et prévue pour différentes stations Météo France.\n",
    "\n",
    "**Attention : Les données météo sont encryptées dans un fichier zip.**  \n",
    "Pour les lire vous avez besoin d'un mot de passe qui ne peut vous être donné que dans le cadre d'un travail au sein de RTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_zip = os.path.join(data_folder, \"meteoX_T0_T24.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "password = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette étape peut être un peu longue car le fichier est volumineux\n",
    "\n",
    "# Pour travailler avec les fichiers zip, on utilise la bibliothèque **zipfile**.\n",
    "zipfile_meteo = zipfile.ZipFile(meteo_zip)\n",
    "zipfile_meteo.setpassword(bytes(password,'utf-8'))\n",
    "meteo_df = pd.read_csv(zipfile_meteo.open('meteoX_T0_T24'),sep=\";\",engine='c',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On se crée une colonne avec des objets timestamp pour les dates\n",
    "meteo_df['ds'] = pd.to_datetime(meteo_df['date'] + ' ' + meteo_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meteo_df.shape)  # (nb lignes , nb_colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meteo_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour la consommation, on ne retient que les données des heures rondes afin de réduire la taille du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "minutes = meteo_df['ds'].dt.minute\n",
    "mask = np.where(minutes.values == 0.0)\n",
    "meteo_horaire_df = meteo_df.loc[mask]\n",
    "\n",
    "# On remet les index au propre\n",
    "meteo_horaire_df = meteo_horaire_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour se mettre dans le cadre d'un exercice de prévision, et toujours dans l'idée de réduire la taille du problème, on ne va conserver que les températures réalisées, les températures prévues à 24h (noms de colonnes finissant par 'Th+24'), ainsi que la colonne _ds_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_a_garder = ['ds'] + list(meteo_horaire_df.columns[meteo_horaire_df.columns.str.endswith(\"Th+0\")]) + list(meteo_horaire_df.columns[meteo_horaire_df.columns.str.endswith(\"Th+24\")])\n",
    "meteo_prev_df = meteo_horaire_df[colonnes_a_garder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meteo_prev_df.head(5))\n",
    "print(meteo_prev_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus : récupération de données depuis internet\n",
    "\n",
    "Dans le but d'automatiser un processus, nous pouvons implémenter une fonction qui va chercher les dernières données mises à disposition sur internet.  \n",
    "\n",
    "Pour l'exemple de la prévision de consommation, il serait pertinent de fournir en entrée du modèle l'information sur le type de jour Tempo. Les clients ayant souscrit à ce type de contrat sont incités à réduire leur consommations les jours BLANC et ROUGE, aussi on peut penser que cette information permettra d'améliorer la qualité des prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulation à la main\n",
    "\n",
    "Avant d'implémenter la version automatique, faisons une fois à la main cette manipulation.\n",
    "\n",
    " - Recupérez à la main le calendrier TEMPO pour 2017-2018 :\n",
    " http://www.rte-france.com/fr/eco2mix/eco2mix-telechargement\n",
    " - Le déposer dans _data&#95;folder_\n",
    " - Le dézipper\n",
    " - Regarder les données dans excel ou autre. Notez en particulier la fin du fichier, la supprimer\n",
    " \n",
    "Importez ces données dans un dataframe avec 'read_excel' de la librairie pandas ou autre méthode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_xls = os.path.join(data_folder, \"eCO2mix_RTE_tempo_2017-2018.xls\")\n",
    "tempo_df = pd.read_csv(tempo_xls, sep=\"\\t\", encoding=\"ISO-8859-1\")  # ce fichier est en fait un csv et non un xls..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tempo_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La même chose automatisée\n",
    "\n",
    "On récupère maintenant automatiquement les informations sur Internet à partir de l'url, sans devoir les chercher à la main soi-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tempo_data(url, data_folder, tempo_xls_zip_name):\n",
    "    \n",
    "    tempo_xls_zip = os.path.join(data_folder, tempo_xls_zip_name)\n",
    "    \n",
    "    # Récupération du fichier zip depuis internet\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    http = urllib3.PoolManager()    \n",
    "    with http.request('GET', url, preload_content=False) as resp, open(tempo_xls_zip, 'wb') as out_file:\n",
    "        shutil.copyfileobj(resp, out_file)\n",
    "        \n",
    "    with zipfile.ZipFile(tempo_xls_zip, \"r\") as zip_file:\n",
    "        zip_file.extractall(data_folder)\n",
    "\n",
    "    # Petite vérification\n",
    "    if not os.path.isfile(tempo_xls_zip):\n",
    "        print(\"ERROR!! {} not found in {}\".format(\"eCO2mix_RTE_tempo_2017-2018.xls\", data_folder))\n",
    "        raise RuntimeError(\"Tempo data not uploaded :-(\")\n",
    "\n",
    "    # Import de ces données dans un dataframe\n",
    "    tempo_df = pd.read_csv(tempo_xls_zip, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "    # Suppression du disclaimer de la dernière ligne de tempo_df, par exemple avec la méthode drop d'un dataframe\n",
    "    last_row = len(tempo_df.index) - 1\n",
    "    tempo_df = tempo_df.drop(tempo_df.index[last_row])\n",
    "\n",
    "    return tempo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste la fonction définie ci-dessus. Parfois pour de sombres raisons de proxy la connection au serveur peut échouer. Comme ce TP porte sur le machine-learning on ne s'acharnera pas sur cette partie en cas d'échec :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://eco2mix.rte-france.com/curves/downloadCalendrierTempo?season=17-18\"\n",
    "#tempo_xls_zip_name = \"eCO2mix_RTE_tempo_2017-2018.zip\"\n",
    "\n",
    "#tempo_df = get_tempo_data(url, data_folder, tempo_xls_zip_name)\n",
    "\n",
    "#print(tempo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les personnes intéressées par le webscrapping, jeter un oeil du côté de <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\" title=\"link to google\">BeautifulSoup</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fusion des données\n",
    "\n",
    "<img src=\"pictures/fusion.png\" width=600 height=200>\n",
    "\n",
    "On va maintenant construire un dataframe unique qui regroupe toutes les données nécessaire à notre modèle de prévision. On aura ici une ligne pour chaque timestamp, et dans cette ligne à la fois notre X et notre Y pour le futur modèle de machine-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans un premier temps, on fusionne la consommation et la température.\n",
    "merged_df = pd.merge(conso_france_horaire_df, meteo_prev_df, on = 'ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.shape)\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on fusionne avec le calendrier des jours fériés en joignant sur la colle \"ds\" des timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, jours_feries_df, how = \"left\", on = \"ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.shape)\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la température France 32 villes \n",
    "\n",
    "On va ajouter une colonne à notre dataframe, colonne que - par expérience/expertise - on sait pouvoir être utile pour prévoir la consommation.\n",
    "\n",
    "La température France est une moyenne pondérée de la température de 32 stations. On a donc besoin des poids de stations_meteo_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "merged_df['FranceTh+0'] = np.dot(merged_df[list(merged_df.columns[merged_df.columns.str.endswith(\"Th+0\")])], stations_meteo_df['Poids'])\n",
    "merged_df['FranceTh+24'] = np.dot(merged_df[list(merged_df.columns[merged_df.columns.str.endswith(\"Th+24\")])], stations_meteo_df['Poids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.shape)\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohérence temporelle des données pour notre modèle de prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenons quelques instants pour regarder les données que l'on a pour l'instant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque point horaire, on a :\n",
    "* la consommation réalisée (au niveau national\n",
    "* la température réalisée pour chaque station météo, ainsi qu'une valeur représentative de la température moyenne à l'échelle nationale\n",
    "* une prévision de température pour 24 heures plus tard pour chaque station météo, ainsi qu'une prévision de la température moyenne France pour dans 24 heures\n",
    "* l'information si le point horaire appartient à un jour férié ou non    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce que l'on veut faire, c'est mettre au point un modèle qui prédit comme Y :\n",
    "* la consommation nationale pour point_horaire_cible\n",
    "prenant en entrée un X qui comporte tout ou partie de :\n",
    "* l'information si point_horaire_cible appartient à un jour férié\n",
    "* La prévision météo pour point_horaire_cible, prévision établie 24h à l'avance\n",
    "* La consommation réalisée 24h avant point_horaire_cible\n",
    "* La température réalisée 24h avant point_horaire_cible\n",
    "Il faut simplement être vigilant sur le fait qu'il est interdit de prédire une consommation pour point horaire cible en ayant comme entrée la température réalisée pour point horaire cible (on n'est pas dans minority report)\n",
    "\n",
    "Ainsi, on va adapter *merged_df* de sorte à ce que chaque ligne correspondent à un point horaire cible à prédire, avec en colonne :\n",
    "* le Y (la consommation nationale pour point_horaire_cible)\n",
    "* Le X (cf. ci-dessus)\n",
    "\n",
    "Ainsi, on va devoir décaler toutes les données de températures de 24 heures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[list(merged_df.columns[merged_df.columns.str.endswith(\"Th+0\")])] = merged_df[list(merged_df.columns[merged_df.columns.str.endswith(\"Th+0\")])].shift(24)\n",
    "merged_df[list(merged_df.columns[merged_df.columns.str.endswith(\"Th+24\")])] = merged_df[list(merged_df.columns[merged_df.columns.str.endswith(\"Th+24\")])].shift(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par souci de clarté on renomme les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [column.replace(\"Th+0\", \"Th_real_24h_avant\").replace(\"Th+24\", \"Th_prev\") for column in merged_df.columns]\n",
    "print(new_columns)\n",
    "\n",
    "merged_df.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.head(3))\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : Attention il est normal que la colonne \"_holiday_\" comporte des NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~merged_df[[\"FranceTh_real_24h_avant\"]].isnull().any(axis=1)\n",
    "merged_df = merged_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.head(3))\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du fichier \n",
    "\n",
    "Tout d'abord on sépare les données en deux : \n",
    "- le vecteur de consommation à prévoir : y_conso\n",
    "- La matrice des variables explicatives : X_input\n",
    "\n",
    "Sachant que plus tard notre modèle aura pour mission d'établir une correspondance _f_ telle que l'on ait du mieux possible une relation *y = f(X)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_conso = merged_df[['ds', 'Consommation.NAT.t0']]\n",
    "y_conso.columns = ['ds', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = merged_df.drop(['Consommation.NAT.t0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_conso.to_csv(\"data/Yconso.csv\", index = False)\n",
    "X_input.to_csv(\"data/Xinput.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et enfin on zip Xinput.csv avec un mot de passe.  \n",
    "Depuis un terminal :\n",
    "\n",
    "> zip -e Xinput.zip Xinput.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation des données \n",
    "\n",
    "La DataScience et le Machine Learning supposent de bien appréhender les données sur lesquelles nos modèles vont être entrainés. Pour cela, il est utile de faire des statistiques descriptives et des visualisations de nos différentes variables.\n",
    "\n",
    "Traitant d'un problème de prévision, on visualisera en particulier des séries temporelles.\n",
    "\n",
    "Vous allez voir des :\n",
    "- échantillons de données\n",
    "- profils de courbe de consommation journaliers et saisonniers\n",
    "- visualisations de corrélation entre conso J et conso retardée\n",
    "\n",
    "## Calcul de statistiques descriptives sur la consommation nationale\n",
    "\n",
    "A l'aide de la fonction *describe*, on calcule les indicateurs classiques. On cherche les données manquantes avec la fonction *isnull*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yconso['ds'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yconso['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yconso['y'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Quelle est la valeur moyenne de la consommation horaire? son min et son max? \n",
    "* Quelle est la période temporelle étudiée?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiser la consommation d'un jour particulier\n",
    "On souhaite visualiser la consommation réalisée pour un jour donné de l'historique. Pour cela on construit une fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_load(var_load, year, month, day, delta_days):\n",
    "    date_cible = pytz.utc.localize(datetime.datetime(year=year, month=month, day=day))\n",
    "    date_lendemain_cible = date_cible + datetime.timedelta(days=delta_days)\n",
    "\n",
    "    conso_periode = var_load[(var_load.ds >= date_cible) \n",
    "                                      & (var_load.ds <= date_lendemain_cible)]\n",
    "    plt.plot(conso_periode['ds'], conso_periode['y'], color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_load(Yconso, 2016, 12, 20,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Afficher un jour ouvré d’hiver, un jour ouvré d’été, commenter.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afficher une semaine arbitraire de consommation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_load(Yconso, 2016, 12, 20, delta_days=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Commenter.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation des profils de la consommation pour les mois d'hiver et les mois d'été\n",
    "Toujours dans le but d'appréhender nos données, on va regarder les profils moyens pour les mois d'été et pour ceux d'hiver. On va également observer le min et le max pour avoir une idée de la variabilité du signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par commodité, on isole le mois pour après attraper les mois d'hiver et d'été\n",
    "Xinput['month'] = Xinput['ds'].dt.month\n",
    "\n",
    "# On isole aussi les heures\n",
    "Xinput['hour'] = Xinput['ds'].dt.hour\n",
    "\n",
    "# On sépare les jours de la semaine \n",
    "# La fonction datetime.weekday() renvoie 0 => Lundi, 1 => Mardi, ..., 5 => Samedi, 6 => Dimanche\n",
    "Xinput['weekday'] = Xinput['ds'].dt.weekday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On aggrège les mois d'hiver ensemble\n",
    "XY_df = pd.merge(Yconso, Xinput, on = 'ds')\n",
    "groupedHiver = XY_df[(XY_df.month == 12) | \n",
    "                                     (XY_df.month == 1) | \n",
    "                                     (XY_df.month == 2)].groupby(['weekday', 'hour'], as_index=True)\n",
    "\n",
    "# Idem pour les mois d'été\n",
    "groupedEte = XY_df[(XY_df.month == 6) | \n",
    "                                   (XY_df.month == 7) | \n",
    "                                   (XY_df.month == 8)].groupby(['weekday', 'hour'], as_index=True)\n",
    "\n",
    "statsHiver = groupedHiver['y'].aggregate([np.mean, np.min, np.max])\n",
    "statsEte = groupedEte['y'].aggregate([np.mean, np.min, np.max])\n",
    "display(statsHiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche des infos sur le profil pour les jours de la semaine\n",
    "# 0 => Lundi, 1 => Mardi, ..., 5 => Samedi, 6 => Dimanche\n",
    "jour = statsHiver.loc[6]  \n",
    "\n",
    "plt.plot(jour['amin'], color='cyan')\n",
    "plt.plot(jour['mean'], color='blue')\n",
    "plt.plot(jour['amax'], color='cyan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lien avec la consommation passée\n",
    "A l'aide de la fonction shift, pour un point horaire cible on regarde  :\n",
    "- la consommation de l'heure précédente, \n",
    "- du jour précédent, \n",
    "- de la semaine précédente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput['lag1H'] = Yconso['y'].shift(1)\n",
    "Xinput['lag1D'] = Yconso['y'].shift(24)\n",
    "Xinput['lag1W'] = Yconso['y'].shift(24*7)\n",
    "\n",
    "Xinput.head(24 * 7 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trace maintenant les nuages de points afin de voir s'il y a corrélation ou non :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_load(var_x):\n",
    "    plt.scatter(Xinput[var_x],Yconso['y'])\n",
    "    plt.title(var_x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_load('lag1H')\n",
    "plot_scatter_load('lag1D')\n",
    "plot_scatter_load('lag1W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "    \n",
    "* Quelle(s) variable(s) vous semble(nt) pertinentes pour construire un modèle de prévision à J+1?\n",
    "\n",
    "* Lesquelles pouvez-vous raisonnablement utiliser dans un processus opérationnel?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiser la consommation en fonction de la température \n",
    "\n",
    "On voudrait savoir si la consommation nationale peut s'expliquer en regardant simplement la température moyenne sur la France. Pour cela, on peut aussi tracer un nuage de points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xinput['Th_prev'], Yconso['y'], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "    \n",
    "* Que pensez-vous de ce nuage ? \n",
    "* Quelles autres variables explicatives proposeriez-vous? De quels types sont-elles?\n",
    "\n",
    "<font color='green'>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
