{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP facultatif : Préparation du jeu de données brut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce TP est de comprendre comment, à partir de différentes sources de données, on construit une première table.\n",
    "Cette table sera ensuite traitée pour constuire le meilleur modèle d'apprentissage possible pour la prévision de consommation nationale.\n",
    "\n",
    "## Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n",
      "Mon repertoire est : D:\\Users\\dordonnatvir\\Documents\\FIFA\\TP_Formation_Conso_MachineLearning\\data\n",
      "Fichiers contenus dans ce répertoire :\n",
      " - communes_coordonnees.csv\n",
      " - eCO2mix_RTE_tempo_2017-2018.xls\n",
      " - eCO2mix_RTE_tempo_2017-2018.zip\n",
      " - joursFeries.csv\n",
      " - meteoX_T0_T24.zip\n",
      " - StationsMeteoRTE.csv\n",
      " - Xinput.csv\n",
      " - Yconso.csv\n",
      " - YconsoT0\n"
     ]
    }
   ],
   "source": [
    "# Exécutez la cellule ci-dessous (par exemple avec shift-entrée)\n",
    "# Si vous exécuter ce notebook depuis votre PC, il faudra peut-etre installer certaines librairies avec \n",
    "# 'pip install ma_librairie'\n",
    "import os  # accès aux commandes système\n",
    "import datetime  # structure de données pour gérer des objets calendaires\n",
    "import pandas as pd  # gérer des tables de données en python\n",
    "import numpy as np  # librairie d'opérations mathématiques\n",
    "import zipfile # manipulation de fichiers zip\n",
    "import urllib3 # téléchargement de fichier\n",
    "data_folder = os.path.join(os.getcwd(),\"data\")\n",
    "%autosave 0\n",
    "\n",
    "print(\"Mon repertoire est : {}\".format(data_folder))\n",
    "print(\"Fichiers contenus dans ce répertoire :\")\n",
    "for file in os.listdir(data_folder):\n",
    "    print(\" - \" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données\n",
    "\n",
    "Dans cette partie nous allons charger les fichiers csv nécessaires pour l'analyse, puis les convertir en data-frame python. Les données de base à récupérer sont :\n",
    "\n",
    "- Les historiques de consommation\n",
    "- Le calendrier des jours fériés\n",
    "- Les données météo, ainsi que la liste des stations\n",
    "- Le calendrier des jours TEMPO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données de consommation\n",
    "\n",
    "Dans un premier temps on importe les données de consommation réalisée à partir du fichier \"YconsoT0\". La date et l'heure sont données et les autres colonnes correspondent aux consommations des 12 régions françaises (hors Corse) et à la consommation nationale.\n",
    "Pour cela on utilise la bibliothèque **pandas** pour la manipulation de données et la fonction **read_csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en tant que data-frame\n",
    "# Remarquez que l'on manipule un gros fichier, ce qui explique pourquoi l'exécution de cette cellule prend du temps\n",
    "conso_csv = os.path.join(data_folder, \"YconsoT0\")\n",
    "conso_df = pd.read_csv(conso_csv, sep=\";\", engine='c', header=0) #engine en language C et position header pour accélérer le chargement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut ensuite vérifier que les données sont importées correctement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156172, 16)\n",
      "Index(['Unnamed: 0', 'date', 'time', 'Consommation.PAC.t0',\n",
      "       'Consommation.PLO.t0', 'Consommation.NOR.t0', 'Consommation.NPP.t0',\n",
      "       'Consommation.LRM.t0', 'Consommation.IDF.t0', 'Consommation.CEN.t0',\n",
      "       'Consommation.BRE.t0', 'Consommation.BFC.t0', 'Consommation.ARA.t0',\n",
      "       'Consommation.ALP.t0', 'Consommation.ACA.t0', 'Consommation.NAT.t0'],\n",
      "      dtype='object')\n",
      "   Unnamed: 0        date   time  Consommation.PAC.t0  Consommation.PLO.t0  \\\n",
      "0           1  2012-12-28  00:00                 5824                 3126   \n",
      "1           2  2012-12-28  00:15                 5949                 2896   \n",
      "2           3  2012-12-28  00:30                 6072                 2670   \n",
      "3           4  2012-12-28  00:45                 6193                 2446   \n",
      "4           5  2012-12-28  01:00                 6312                 2226   \n",
      "\n",
      "   Consommation.NOR.t0  Consommation.NPP.t0  Consommation.LRM.t0  \\\n",
      "0                 3417                 5677                 4686   \n",
      "1                 3286                 5525                 4420   \n",
      "2                 3158                 5374                 4158   \n",
      "3                 3031                 5226                 3899   \n",
      "4                 2906                 5081                 3644   \n",
      "\n",
      "   Consommation.IDF.t0  Consommation.CEN.t0  Consommation.BRE.t0  \\\n",
      "0                 8514                 2164                 2684   \n",
      "1                 8210                 2012                 2505   \n",
      "2                 7910                 1862                 2328   \n",
      "3                 7614                 1715                 2153   \n",
      "4                 7322                 1569                 1981   \n",
      "\n",
      "   Consommation.BFC.t0  Consommation.ARA.t0  Consommation.ALP.t0  \\\n",
      "0                 2222                 7718                 5381   \n",
      "1                 2156                 7495                 5340   \n",
      "2                 2091                 7275                 5300   \n",
      "3                 2026                 7059                 5261   \n",
      "4                 1963                 6845                 5222   \n",
      "\n",
      "   Consommation.ACA.t0  Consommation.NAT.t0  \n",
      "0                 4681                59679  \n",
      "1                 4552                59632  \n",
      "2                 4426                58103  \n",
      "3                 4301                56438  \n",
      "4                 4178                55354  \n"
     ]
    }
   ],
   "source": [
    "# Afficher les dimensions et le noms des colonnes de la data frame\n",
    "print(conso_df.shape)\n",
    "print(conso_df.columns)\n",
    "print(conso_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La composante temporelle pour une problématique de prévision\n",
    "\n",
    "<img src=\"pictures/clock.png\" width=60 height=60>\n",
    "\n",
    "Le fichier conso_Y.csv contient en particulier 2 colonnes 'date' et 'time', les deux contenant des objets de type \"string\" correspondant à la date et à l'heure. Nous allons fusionner ces informations en une nouvelle colonne\n",
    "d'objets \"ds\" (dateStamp) mieux adaptés pour la manipulation de dates et d'heures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_df['ds'] = pd.to_datetime(conso_df['date'] + \" \" + conso_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-28 00:00:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-28 00:15:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-28 00:30:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-28 00:45:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-28 01:00:00</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds        date   time\n",
       "0 2012-12-28 00:00:00  2012-12-28  00:00\n",
       "1 2012-12-28 00:15:00  2012-12-28  00:15\n",
       "2 2012-12-28 00:30:00  2012-12-28  00:30\n",
       "3 2012-12-28 00:45:00  2012-12-28  00:45\n",
       "4 2012-12-28 01:00:00  2012-12-28  01:00"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conso_df[['ds', 'date', 'time']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour manipuler des dates (effectuer des tris, des sélections, récupérer si c'est un lundi, mardi,...), il est plus efficace de passer par un objet \"datetime\" plutôt que de se débrouiller en manipulant des chaînes de caractères.\n",
    "\n",
    "La cellule ci-dessous a pour but d'illustrer comment utiliser ces objets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noel_2017_date vaut : 2017-12-25 ; et est de type <class 'datetime.date'>\n",
      "noel_2017_str vaut : 2017-12-25 ; et est de type <class 'str'>\n",
      "starwars_day_2017_date vaut : 2017-05-04 00:00:00 ; et est de type <class 'datetime.datetime'>\n",
      "starwars_day_2017_str vaut : 2017-05-04 ; et est de type <class 'str'>\n",
      "2018-01-01\n"
     ]
    }
   ],
   "source": [
    "# datetime vers string\n",
    "noel_2017_date = datetime.date(2017, 12, 25)\n",
    "noel_2017_str = datetime.datetime.strftime(noel_2017_date, format=\"%Y-%m-%d\")\n",
    "print(\"noel_2017_date vaut : {} ; et est de type {}\".format(noel_2017_date, str(type(noel_2017_date))))\n",
    "print(\"noel_2017_str vaut : {} ; et est de type {}\".format(noel_2017_str, str(type(noel_2017_str))))\n",
    "\n",
    "# string vers datetime\n",
    "starwars_day_2017_str = \"2017-05-04\"\n",
    "starwars_day_2017_date = datetime.datetime.strptime(starwars_day_2017_str, \"%Y-%m-%d\")\n",
    "print(\"starwars_day_2017_date vaut : {} ; et est de type {}\".format(starwars_day_2017_date, str(type(starwars_day_2017_date))))\n",
    "print(\"starwars_day_2017_str vaut : {} ; et est de type {}\".format(starwars_day_2017_str, str(type(starwars_day_2017_str))))\n",
    "\n",
    "# Voyager dans le temps\n",
    "saint_sylvestre_2017_date = datetime.date(2017, 12, 31)\n",
    "bienvenu_en_2018_date = saint_sylvestre_2017_date + datetime.timedelta(days=1)\n",
    "print(bienvenu_en_2018_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduire notre problème\n",
    "\n",
    "Le dataframe de consommation est volumineux, et contient beaucoup d'information inutile (au moins en première approximation) pour notre problème de prévision de la consommation nationale. On va donc simplifier.\n",
    "\n",
    "On va se concentrer sur la consommation à l'échelle nationale **au pas horaire**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on commence par ecarter les colonnes inutiles\n",
    "consoFrance_df = conso_df[['ds', 'Consommation.NAT.t0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et maintenant on ne garde que les heures pleines\n",
    "minutes = consoFrance_df['ds'].dt.minute\n",
    "indices_hours = np.where(minutes.values == 0.0)\n",
    "consoFranceHoraire_df = consoFrance_df.loc[indices_hours]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds  Consommation.NAT.t0\n",
      "0 2012-12-28 00:00:00                59679\n",
      "1 2012-12-28 01:00:00                55354\n",
      "2 2012-12-28 02:00:00                54324\n",
      "3 2012-12-28 03:00:00                52066\n",
      "4 2012-12-28 04:00:00                49684\n",
      "(39043, 2)\n"
     ]
    }
   ],
   "source": [
    "# les index de ce sous-dataframe correspondent à celle du dataframe de base,\n",
    "# et donc sont pour l'instant des multiples de 4.\n",
    "# on va les réinitialiser pour avoir une dataframe \"neuve\"\n",
    "consoFranceHoraire_df = consoFranceHoraire_df.reset_index(drop=True)  \n",
    "print(consoFranceHoraire_df.head(5))\n",
    "print(consoFranceHoraire_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récuperation des jours fériés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "jours_feries_csv = os.path.join(data_folder,\"joursFeries.csv\")\n",
    "jours_feries_df = pd.read_csv(jours_feries_csv, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour la première colonne, les dates sont au format \"string\"\n",
    "# Nous allons les convertir en objet \"datetime\" mieux adaptés pour la manipulation de dates\n",
    "jours_feries_df.ds = pd.to_datetime(jours_feries_df.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>Noel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NouvelAn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>Paques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>1erMai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>8Mai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-05-09</td>\n",
       "      <td>Ascension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-05-20</td>\n",
       "      <td>Pentecote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-07-14</td>\n",
       "      <td>FeteNationale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds        holiday\n",
       "0 2012-12-25           Noel\n",
       "1 2013-01-01       NouvelAn\n",
       "2 2013-04-01         Paques\n",
       "3 2013-05-01         1erMai\n",
       "4 2013-05-08           8Mai\n",
       "5 2013-05-09      Ascension\n",
       "6 2013-05-20      Pentecote\n",
       "7 2013-07-14  FeteNationale"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regardons la tête des données\n",
    "jours_feries_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des stations météo\n",
    "\n",
    "NB - Pour en savoir plus sur les poids :  \n",
    "https://clients.rte-france.com/lang/fr/visiteurs/services/actualites.jsp?id=9482&mode=detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_meteo_csv = os.path.join(data_folder, \"StationsMeteoRTE.csv\")\n",
    "stations_meteo_df = pd.read_csv(stations_meteo_csv, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Nom</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>Poids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>BOULOGNE-SUR-MER</td>\n",
       "      <td>1.616670</td>\n",
       "      <td>50.716670</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>1.833330</td>\n",
       "      <td>50.100000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>LILLE</td>\n",
       "      <td>3.058580</td>\n",
       "      <td>50.632970</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>CAEN</td>\n",
       "      <td>-0.359120</td>\n",
       "      <td>49.185850</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>REIMS</td>\n",
       "      <td>4.031696</td>\n",
       "      <td>49.258329</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID               Nom  longitude   latitude  Poids\n",
       "0   2  BOULOGNE-SUR-MER   1.616670  50.716670  0.010\n",
       "1   5         ABBEVILLE   1.833330  50.100000  0.010\n",
       "2  15             LILLE   3.058580  50.632970  0.030\n",
       "3  27              CAEN  -0.359120  49.185850  0.025\n",
       "4  70             REIMS   4.031696  49.258329  0.000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_meteo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "nstations = stations_meteo_df.shape[0]\n",
    "print(nstations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GMapOptions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-e8896bdea78d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmap_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGMapOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m47.08\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.39\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"roadmap\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGMapPlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRange1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRange1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmap_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"France\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GMapOptions' is not defined"
     ]
    }
   ],
   "source": [
    "map_options = GMapOptions(lat=47.08, lng=2.39, map_type=\"roadmap\", zoom=6)\n",
    "\n",
    "plot = GMapPlot(x_range=Range1d(), y_range=Range1d(), map_options=map_options)\n",
    "plot.title.text = \"France\"\n",
    "\n",
    "# For GMaps to function, Google requires you obtain and enable an API key:\n",
    "#\n",
    "#     https://developers.google.com/maps/documentation/javascript/get-api-key\n",
    "#\n",
    "# Replace the value below with your personal API key:\n",
    "plot.api_key = \"AIzaSyC05Bs_e0q6KWyVHlmy0ymHMKMknyMbCm0\"\n",
    "tempInstant1 = meteo_obs_df.iloc[0, np.arange(0, 35)]\n",
    "\n",
    "# nos données d'intérêt pour créer notre visualisation\n",
    "data=dict(lat=stations_meteo_df['latitude'],\n",
    "          lon=stations_meteo_df['longitude'],\n",
    "          label=stations_meteo_df['Nom'],\n",
    "          temp=tempInstant1)\n",
    "\n",
    "source = ColumnDataSource(data)\n",
    "\n",
    "# l'échelle de couleur pour la température\n",
    "Tlow=0\n",
    "Thigh=20\n",
    "color_mapper = LogColorMapper(palette=\"Viridis256\", low=Tlow, high=Thigh)\n",
    "\n",
    "# la couleur de remplissage des cercles est fonction de la valeur de la temérature\n",
    "circle = Circle(x=\"lon\", y=\"lat\", size=15, fill_color={'field': 'temp', 'transform': color_mapper},\n",
    "                fill_alpha=0.8, line_color=None,)\n",
    "\n",
    "# les labels que l'on souhaite afficher en passant un curseur sur une station\n",
    "labels = LabelSet(x='lon', y='lat', text='label', level='glyph', x_offset=5, y_offset=5,\n",
    "                  source=source, render_mode='canvas')\n",
    "\n",
    "# on ajoute la layer\n",
    "plot.add_glyph(source, circle)\n",
    "\n",
    "# le tooltip quand on pose le curseur dessus\n",
    "hover = HoverTool(tooltips= OrderedDict([\n",
    "    (\"index\", \"$index\"),\n",
    "    (\"(xx,yy)\", \"(@lon, @lat)\"),\n",
    "    (\"label\", \"@label\"),\n",
    "    (\"T\", \"@temp\")\n",
    "]))\n",
    "\n",
    "# on plot\n",
    "plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool(), hover)\n",
    "\n",
    "\n",
    "color_bar = ColorBar(color_mapper=color_mapper, ticker=LogTicker(),\n",
    "                 label_standoff=12, border_line_color=None, location=(0,0))\n",
    "plot.add_layout(color_bar, 'right')\n",
    "\n",
    "output_notebook()#\"gmap_plot.html\"\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération du dataframe de météo\n",
    "<img src=\"pictures/weather.png\" width=60 height=60>\n",
    "\n",
    "On va utiliser les mêmes fonctions que précédemment pour lire le fichier **'meteoX_T.csv'**, qui est situé dans data_folder et contient les historiques de température réalisée et prévue pour différentes stations Météo France.\n",
    "\n",
    "Importez-les dans un dataframe _meteo&#95;df_\n",
    "et regardez à quoi elles ressemblent. Pensez aussi à changer les dates _string_ vers le format _datetime_.\n",
    "\n",
    "** Attention : Les données météo sont encryptées dans un fichier zip.** \n",
    "Pour les lire vous avez besoin d'un mot de passe qui ne peut vous être donné que dans le cadre d'un travail au sein de RTE.\n",
    "Pour travailler avec les fichiers zip, on utilise la bibliothèque **zipfile**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#password = None\n",
    "password = \"FIFA_Meteo\"\n",
    "# TODO: charger \"meteoX_T.csv\" dans \"meteo_df\"\n",
    "meteo_zip = os.path.join(data_folder, \"meteoX_T0_T24.zip\")\n",
    "zfMeteo = zipfile.ZipFile(meteo_zip)#.extractall(pwd=bytes(password,'utf-8'))\n",
    "zfMeteo.setpassword(bytes(password,'utf-8'))\n",
    "meteo_df = pd.read_csv(zfMeteo.open('meteoX_T0_T24'),sep=\";\",engine='c',header=0)\n",
    "# END\n",
    "\n",
    "# TODO: créer une colonne \"ds\" dans \"meteo_df\" comme précédemment\n",
    "meteo_df['ds'] = pd.to_datetime(meteo_df['date'] + ' ' + meteo_df['time'])\n",
    "# END\n",
    "\n",
    "#transformer le type des colonnes temperatures en numerique si ce n'était pas le cas\n",
    "tempCols = [col for col in meteo_df.columns if 'Th' in col]\n",
    "meteo_df[tempCols] = meteo_df[tempCols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        date   time  X002Th+0  X005Th+0  X015Th+0  X027Th+0  \\\n",
      "0           1  2012-12-28  00:00       9.5      11.9      10.5     11.70   \n",
      "1           2  2012-12-28  00:15       9.5      11.9      10.5     11.70   \n",
      "2           3  2012-12-28  00:30       9.5      11.9      10.5     11.70   \n",
      "3           4  2012-12-28  00:45       9.5      11.9      10.5     11.70   \n",
      "4           5  2012-12-28  01:00       9.5      11.9      10.5     11.69   \n",
      "\n",
      "   X070Th+0  X110Th+0  X120Th+0         ...          X588Th+24  X621Th+24  \\\n",
      "0     10.10      12.4     13.00         ...                9.7       11.6   \n",
      "1     10.10      12.4     13.00         ...                9.7       11.6   \n",
      "2     10.10      12.4     13.00         ...                9.7       11.6   \n",
      "3     10.10      12.4     13.01         ...                9.7       11.6   \n",
      "4     10.11      12.4     13.01         ...                9.7       11.6   \n",
      "\n",
      "   X630Th+24  X643Th+24  X645Th+24  X650Th+24  X675Th+24  X690Th+24  \\\n",
      "0        7.6        9.9       11.1       11.6       11.8       11.1   \n",
      "1        7.6        9.9       11.1       11.6       11.8       11.1   \n",
      "2        7.6        9.9       11.1       11.6       11.8       11.1   \n",
      "3        7.6        9.9       11.1       11.6       11.8       11.1   \n",
      "4        7.6        9.9       11.1       11.6       11.8       11.1   \n",
      "\n",
      "   X747Th+24                  ds  \n",
      "0      12.00 2012-12-28 00:00:00  \n",
      "1      12.00 2012-12-28 00:15:00  \n",
      "2      12.00 2012-12-28 00:30:00  \n",
      "3      12.00 2012-12-28 00:45:00  \n",
      "4      12.01 2012-12-28 01:00:00  \n",
      "\n",
      "[5 rows x 74 columns]\n",
      "(156176, 74)\n"
     ]
    }
   ],
   "source": [
    "# TODO: afficher les 5 premières lignes de \"meteo_df\"\n",
    "print(meteo_df.head(5))\n",
    "print(meteo_df.shape)\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour la consommation, on ne retient que les données des heures rondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = meteo_df['ds'].dt.minute\n",
    "mask = np.where(minutes.values == 0.0)\n",
    "meteoHoraire_df = meteo_df.loc[mask]\n",
    "meteoHoraire_df = meteoHoraire_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour se mettre dans le cadre d'un exercice de prévision on ne va conserver que les températures prévues à 24h (noms de colonnes finissant par 'Th+24'), ainsi que la colonne _ds_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_prev_df = meteoHoraire_df[['ds']+list(meteoHoraire_df.columns[meteoHoraire_df.columns.str.endswith(\"Th+24\")]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ds  X002Th+24  X005Th+24  X015Th+24  X027Th+24  X070Th+24  \\\n",
      "0 2012-12-28 00:00:00       9.50      11.30      11.00      10.40      11.80   \n",
      "1 2012-12-28 01:00:00       9.50      11.31      11.00      10.40      11.80   \n",
      "2 2012-12-28 02:00:00       9.49      11.32      10.99      10.39      11.79   \n",
      "3 2012-12-28 03:00:00       9.49      11.34      10.98      10.37      11.79   \n",
      "4 2012-12-28 04:00:00       9.48      11.37      10.97      10.35      11.78   \n",
      "\n",
      "   X110Th+24  X120Th+24  X130Th+24  X145Th+24    ...      X579Th+24  \\\n",
      "0      10.40       9.10      10.90      10.40    ...           9.50   \n",
      "1      10.40       9.10      10.89      10.40    ...           9.51   \n",
      "2      10.41       9.09      10.87      10.39    ...           9.52   \n",
      "3      10.42       9.08      10.85      10.39    ...           9.54   \n",
      "4      10.44       9.07      10.81      10.38    ...           9.57   \n",
      "\n",
      "   X588Th+24  X621Th+24  X630Th+24  X643Th+24  X645Th+24  X650Th+24  \\\n",
      "0       9.70       11.6       7.60       9.90      11.10      11.60   \n",
      "1       9.70       11.6       7.60       9.90      11.10      11.60   \n",
      "2       9.71       11.6       7.60       9.91      11.11      11.61   \n",
      "3       9.72       11.6       7.61       9.91      11.11      11.61   \n",
      "4       9.74       11.6       7.62       9.92      11.12      11.62   \n",
      "\n",
      "   X675Th+24  X690Th+24  X747Th+24  \n",
      "0      11.80      11.10      12.00  \n",
      "1      11.80      11.10      12.01  \n",
      "2      11.81      11.10      12.02  \n",
      "3      11.81      11.11      12.04  \n",
      "4      11.82      11.11      12.06  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "(39049, 36)\n"
     ]
    }
   ],
   "source": [
    "print(meteo_prev_df.head(5))\n",
    "print(meteo_prev_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion des données\n",
    "<img src=\"pictures/fusion.png\" width=600 height=200>\n",
    "\n",
    "On va maintenant construire un dataframe, issu de la fusion entre les données de consommation, de prévision de tempérture et de jours fériés.\n",
    "\n",
    "Dans un premier temps, on fusionne la consommation et la température."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput = pd.merge(consoFranceHoraire_df, meteo_prev_df, on = 'ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39049, 37)\n",
      "Index(['ds', 'Consommation.NAT.t0', 'X002Th+24', 'X005Th+24', 'X015Th+24',\n",
      "       'X027Th+24', 'X070Th+24', 'X110Th+24', 'X120Th+24', 'X130Th+24',\n",
      "       'X145Th+24', 'X149Th+24', 'X156Th+24', 'X168Th+24', 'X180Th+24',\n",
      "       'X190Th+24', 'X222Th+24', 'X240Th+24', 'X255Th+24', 'X260Th+24',\n",
      "       'X280Th+24', 'X299Th+24', 'X434Th+24', 'X460Th+24', 'X481Th+24',\n",
      "       'X497Th+24', 'X510Th+24', 'X579Th+24', 'X588Th+24', 'X621Th+24',\n",
      "       'X630Th+24', 'X643Th+24', 'X645Th+24', 'X650Th+24', 'X675Th+24',\n",
      "       'X690Th+24', 'X747Th+24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xinput.shape)\n",
    "print(Xinput.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on fusionne avec le calendrier des jours fériés (**Attention : left join**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput = pd.merge(Xinput,jours_feries_df,how = \"left\", on = \"ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39049, 38)\n",
      "Index(['ds', 'Consommation.NAT.t0', 'X002Th+24', 'X005Th+24', 'X015Th+24',\n",
      "       'X027Th+24', 'X070Th+24', 'X110Th+24', 'X120Th+24', 'X130Th+24',\n",
      "       'X145Th+24', 'X149Th+24', 'X156Th+24', 'X168Th+24', 'X180Th+24',\n",
      "       'X190Th+24', 'X222Th+24', 'X240Th+24', 'X255Th+24', 'X260Th+24',\n",
      "       'X280Th+24', 'X299Th+24', 'X434Th+24', 'X460Th+24', 'X481Th+24',\n",
      "       'X497Th+24', 'X510Th+24', 'X579Th+24', 'X588Th+24', 'X621Th+24',\n",
      "       'X630Th+24', 'X643Th+24', 'X645Th+24', 'X650Th+24', 'X675Th+24',\n",
      "       'X690Th+24', 'X747Th+24', 'holiday'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xinput.shape)\n",
    "print(Xinput.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la température France 32 villes \n",
    "La température France est une moyenne pondérée de la température de 32 stations. On a donc besoin des poids de stations_meteo_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput['FranceTh+24'] = np.dot(Xinput[list(Xinput.columns[Xinput.columns.str.endswith(\"Th+24\")])],stations_meteo_df['Poids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39049, 39)\n",
      "Index(['ds', 'Consommation.NAT.t0', 'X002Th+24', 'X005Th+24', 'X015Th+24',\n",
      "       'X027Th+24', 'X070Th+24', 'X110Th+24', 'X120Th+24', 'X130Th+24',\n",
      "       'X145Th+24', 'X149Th+24', 'X156Th+24', 'X168Th+24', 'X180Th+24',\n",
      "       'X190Th+24', 'X222Th+24', 'X240Th+24', 'X255Th+24', 'X260Th+24',\n",
      "       'X280Th+24', 'X299Th+24', 'X434Th+24', 'X460Th+24', 'X481Th+24',\n",
      "       'X497Th+24', 'X510Th+24', 'X579Th+24', 'X588Th+24', 'X621Th+24',\n",
      "       'X630Th+24', 'X643Th+24', 'X645Th+24', 'X650Th+24', 'X675Th+24',\n",
      "       'X690Th+24', 'X747Th+24', 'holiday', 'FranceTh+24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xinput.shape)\n",
    "print(Xinput.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohérence temporelle des données\n",
    "\n",
    "Pour avoir la prévision de température à 24h pour l'observation t, il faut décaler les données de température de 24 pas de temps !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput[list(Xinput.columns[Xinput.columns.str.endswith(\"Th+24\")])] = Xinput[list(Xinput.columns[Xinput.columns.str.endswith(\"Th+24\")])].shift(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus : récupération de données depuis internet\n",
    "\n",
    "Dans le but d'automatiser un processus, nous pouvons implémenter une fonction qui ira chercher les dernières données mises à disposition sur internet.  \n",
    "\n",
    "Pour cet exemple nous allons considérer les jours Tempo, et (si le temps le permet en fin de TP) tester si cette information permet d'améliorer la qualité des prédictions.\n",
    "\n",
    "### Manipulation à la main\n",
    "\n",
    " - Recupérez à la main le calendrier TEMPO pour 2017-2018 :\n",
    " http://www.rte-france.com/fr/eco2mix/eco2mix-telechargement\n",
    " - Le déposer dans _data&#95;folder_\n",
    " - Le dézipper\n",
    " - Regarder les données dans excel ou autre. Notez en particulier la fin du fichier, la supprimer\n",
    " \n",
    "Importez ces données dans un dataframe avec 'read_excel' de la librairie pandas ou autre méthode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_xls = os.path.join(data_folder, \"eCO2mix_RTE_tempo_2017-2018.xls\")\n",
    "tempo_df = pd.read_csv(tempo_xls, sep=\"\\t\", encoding=\"ISO-8859-1\")  # ce fichier est en fait un csv et non un xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Type de jour TEMPO\n",
      "0  01/09/2017               BLEU\n",
      "1  02/09/2017               BLEU\n",
      "2  03/09/2017               BLEU\n",
      "3  04/09/2017               BLEU\n",
      "4  05/09/2017               BLEU\n"
     ]
    }
   ],
   "source": [
    "print(tempo_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La même chose automatisée\n",
    "\n",
    "On récupère automatiquement les informations sur Internet à partir de l'url, sans devoir les chercher à la main soi-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tempo_data(url, data_folder, tempo_xls_zip_name):\n",
    "    \n",
    "    tempo_xls_zip = os.path.join(data_folder, tempo_xls_zip_name)\n",
    "    \n",
    "    # Récupération du fichier zip depuis internet\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    http = urllib3.PoolManager()    \n",
    "    with http.request('GET', url, preload_content=False) as resp, open(tempo_xls_zip, 'wb') as out_file:\n",
    "        shutil.copyfileobj(resp, out_file)\n",
    "        \n",
    "    with zipfile.ZipFile(tempo_xls_zip, \"r\") as zip_file:\n",
    "        zip_file.extractall(data_folder)\n",
    "\n",
    "    # Petite vérification\n",
    "    if not os.path.isfile(tempo_xls_zip):\n",
    "        print(\"ERROR!! {} not found in {}\".format(\"eCO2mix_RTE_tempo_2017-2018.xls\", data_folder))\n",
    "        raise RuntimeError(\"Tempo data not uploaded :-(\")\n",
    "\n",
    "    # Import de ces données dans un dataframe\n",
    "    tempo_df = pd.read_csv(tempo_xls_zip, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
    "    # Suppression du disclaimer de la dernière ligne de tempo_df, par exemple avec la méthode drop d'un dataframe\n",
    "    last_row = len(tempo_df.index) - 1\n",
    "    tempo_df = tempo_df.drop(tempo_df.index[last_row])\n",
    "\n",
    "    return tempo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPSConnectionPool(host='eco2mix.rte-france.com', port=443): Max retries exceeded with url: /curves/downloadCalendrierTempo?season=17-18 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000000009DC84A8>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 159\u001b[1;33m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11004] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 168\u001b[1;33m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x0000000009DC84A8>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-54399d123b64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtempo_xls_zip_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"eCO2mix_RTE_tempo_2017-2018.zip\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtempo_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tempo_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempo_xls_zip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempo_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-a7b5a224b77c>\u001b[0m in \u001b[0;36mget_tempo_data\u001b[1;34m(url, data_folder, tempo_xls_zip_name)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0murllib3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInsecureRequestWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mhttp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPoolManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreload_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempo_xls_zip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     66\u001b[0m             return self.request_encode_url(method, url, fields=fields,\n\u001b[0;32m     67\u001b[0m                                            \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                                            **urlopen_kw)\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'?'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     def request_encode_body(self, method, url, fields=None, headers=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                 \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                                 **response_kw)\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdrain_and_release_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                 \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                                 **response_kw)\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdrain_and_release_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                 \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                 \u001b[0mrelease_conn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                                 **response_kw)\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdrain_and_release_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Incremented Retry for (url='%s'): %r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='eco2mix.rte-france.com', port=443): Max retries exceeded with url: /curves/downloadCalendrierTempo?season=17-18 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x0000000009DC84A8>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "## Test de la fonction définie ci-dessus\n",
    "url = \"https://eco2mix.rte-france.com/curves/downloadCalendrierTempo?season=17-18\"\n",
    "tempo_xls_zip_name = \"eCO2mix_RTE_tempo_2017-2018.zip\"\n",
    "\n",
    "tempo_df = get_tempo_data(url, data_folder, tempo_xls_zip_name)\n",
    "\n",
    "print(tempo_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les personnes intéressées par le webscrapping, jeter un oeil du côté de <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\" title=\"link to google\">BeautifulSoup</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du fichier \n",
    "\n",
    "Tout d'abord on sépare les données en deux : \n",
    "- le vecteur de consommation à prévoir : Yconso\n",
    "- La matrice des variables explicatives : Xinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yconso = Xinput[['ds','Consommation.NAT.t0']]\n",
    "Yconso.columns = ['ds', 'y']\n",
    "\n",
    "Xinput = Xinput.drop(['Consommation.NAT.t0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yconso.to_csv(\"data/Yconso.csv\", index = False)\n",
    "Xinput.to_csv(\"data/Xinput.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
